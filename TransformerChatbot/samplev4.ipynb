{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Import Libraries",
   "id": "bda64367047c0158"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-27T23:32:58.183338Z",
     "start_time": "2025-04-27T23:32:56.595714Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from collections import Counter\n",
    "import json\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.utils.data\n",
    "import math\n",
    "import torch.nn.functional as F\n",
    "import re\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "import unicodedata\n",
    "import os\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = '1'\n",
    "nltk.download('punkt')\n",
    "\n",
    "nltk.download('punkt_tab')"
   ],
   "id": "f28330a8d1e8a68c",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/leviathan/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     /home/leviathan/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Define Constants",
   "id": "9529ea69abfd03f1"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-27T23:32:58.230426Z",
     "start_time": "2025-04-27T23:32:58.229059Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# File paths\n",
    "CORPUS_CONV = 'data/cornell movie-dialogs corpus/movie_conversations.txt'\n",
    "CORPUS_LINES = 'data/cornell movie-dialogs corpus/movie_lines.txt'\n",
    "max_len = 13\n",
    "DELIMITER = ' +++$+++ '"
   ],
   "id": "2389eb13bb6baf43",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Loading Files",
   "id": "8733398db0ebbfd"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-27T23:32:58.238213Z",
     "start_time": "2025-04-27T23:32:58.236327Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def load_conversations():\n",
    "    \"\"\"Load and parse conversation files with error handling\"\"\"\n",
    "    try:\n",
    "        with open(CORPUS_CONV, 'r', encoding='iso-8859-1') as f:\n",
    "            conversations = f.readlines()\n",
    "        with open(CORPUS_LINES, 'r', encoding='iso-8859-1') as f:\n",
    "            lines = f.readlines()\n",
    "        return conversations, lines\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading files: {e}\")\n",
    "        return None, None\n",
    "\n",
    "def create_lines_dict(lines):\n",
    "    \"\"\"Create dictionary of line ID to text with better parsing\"\"\"\n",
    "    lines_dict = {}\n",
    "    for line in lines:\n",
    "        parts = line.split(DELIMITER)\n",
    "        if len(parts) >= 2:\n",
    "            lines_dict[parts[0]] = parts[-1].strip()\n",
    "\n",
    "    return lines_dict"
   ],
   "id": "19c01d505729658",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Text Preprocessing",
   "id": "4b12f66b065b545f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-27T23:32:58.282165Z",
     "start_time": "2025-04-27T23:32:58.280428Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def preprocess_text(text):\n",
    "    \"\"\"Improved text preprocessing\"\"\"\n",
    "    # Convert to lowercase and normalize unicode\n",
    "    text = text.lower()\n",
    "    text = unicodedata.normalize('NFKD', text).encode('ascii', 'ignore').decode()\n",
    "\n",
    "    # Remove special characters but keep apostrophes for contractions\n",
    "    text = re.sub(r'[^a-zA-Z0-9\\'\\s]', ' ', text)\n",
    "\n",
    "    # Standardize contractions\n",
    "    text = re.sub(r\"\\'s\", \" is\", text)\n",
    "    text = re.sub(r\"\\'re\", \" are\", text)\n",
    "    text = re.sub(r\"\\'t\", \" not\", text)\n",
    "    text = re.sub(r\"\\'ll\", \" will\", text)\n",
    "    text = re.sub(r\"\\'ve\", \" have\", text)\n",
    "    text = re.sub(r\"\\'m\", \" am\", text)\n",
    "    text = re.sub(r\"won't\", \"will not\", text)\n",
    "    text = re.sub(r\"can't\", \"cannot\", text)\n",
    "\n",
    "    # Remove extra whitespace\n",
    "    text = ' '.join(text.split())\n",
    "    return text"
   ],
   "id": "5202af0432a1c773",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Extract Conversation Pairs",
   "id": "5b255474fc56b0fe"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-27T23:32:58.326520Z",
     "start_time": "2025-04-27T23:32:58.324488Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def extract_pairs(conversations, lines_dict):\n",
    "    \"\"\"Extract and preprocess conversation pairs\"\"\"\n",
    "    pairs = []\n",
    "    for conv in conversations:\n",
    "        try:\n",
    "            ids = eval(conv.split(DELIMITER)[-1])\n",
    "            for i in range(len(ids) - 1):\n",
    "                first = lines_dict.get(ids[i], '')\n",
    "                second = lines_dict.get(ids[i + 1], '')\n",
    "\n",
    "                if first and second:\n",
    "                    first = preprocess_text(first)\n",
    "                    second = preprocess_text(second)\n",
    "\n",
    "                    # Add debug prints to see the text before tokenization\n",
    "                    # print(f\"Pre-tokenization first: '{first}'\")\n",
    "                    # print(f\"Pre-tokenization second: '{second}'\")\n",
    "\n",
    "                    try:\n",
    "                        first_tokens = word_tokenize(first)[:max_len]\n",
    "                        second_tokens = word_tokenize(second)[:max_len]\n",
    "                    except Exception as e:\n",
    "                        print(f\"Tokenization error: {e}\")\n",
    "                        continue\n",
    "                    #\n",
    "                    # print(f'Tokens first: {first_tokens}')\n",
    "                    # print(f'Tokens second: {second_tokens}')\n",
    "\n",
    "                    if first_tokens and second_tokens:  # Only add if both have content\n",
    "                        pairs.append([first_tokens, second_tokens])\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing conversation: {e}\")\n",
    "            continue\n",
    "\n",
    "    print(f\"Total pairs extracted: {len(pairs)}\")\n",
    "    return pairs"
   ],
   "id": "e45c3ae77a60f8d4",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Build Vocabulary",
   "id": "7bec7163cf064c60"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-27T23:32:58.370885Z",
     "start_time": "2025-04-27T23:32:58.368642Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def build_vocab(pairs, min_freq=1):\n",
    "    \"\"\"Build vocabulary with proper ID allocation\"\"\"\n",
    "    word_freq = Counter()\n",
    "    for pair in pairs:\n",
    "        word_freq.update(pair[0])\n",
    "        word_freq.update(pair[1])\n",
    "\n",
    "    # Filter out rare words\n",
    "    words = [w for w, freq in word_freq.items() if freq >= min_freq]\n",
    "\n",
    "    # Start with special tokens to ensure they have predictable IDs\n",
    "    special_tokens = ['<pad>', '<unk>', '<start>', '<end>']\n",
    "\n",
    "    # Create word map with continuous IDs\n",
    "    word_map = {}\n",
    "    # First add special tokens\n",
    "    for i, token in enumerate(special_tokens):\n",
    "        word_map[token] = i\n",
    "\n",
    "    # Then add all other words\n",
    "    for i, word in enumerate(words):\n",
    "        if word not in word_map:  # Skip if it's somehow a special token\n",
    "            word_map[word] = i + len(special_tokens)\n",
    "\n",
    "    print(f\"Final vocabulary size: {len(word_map)}\")\n",
    "    return word_map"
   ],
   "id": "58eacb5b065f2d17",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Encoding Sequences",
   "id": "e1788afa44aa9a4f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-27T23:32:58.413010Z",
     "start_time": "2025-04-27T23:32:58.411171Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def encode_sequence(tokens, word_map, is_reply=False, max_seq_len=5):\n",
    "    \"\"\"Encode sequence with correct length handling\"\"\"\n",
    "    if is_reply:\n",
    "        # For replies, we need to account for <start> and <end> tokens\n",
    "        # So actual token count will be limited to max_seq_len-2\n",
    "        tokens = tokens[:max_seq_len-2]  # Limit tokens to leave room for special tokens\n",
    "\n",
    "        # Add start token, tokens, and end token\n",
    "        encoded = [word_map['<start>']]\n",
    "        encoded.extend([word_map.get(token, word_map['<unk>']) for token in tokens])\n",
    "        encoded.append(word_map['<end>'])\n",
    "    else:\n",
    "        # For questions, we can use all max_seq_len positions\n",
    "        tokens = tokens[:max_seq_len]  # Limit tokens to max_seq_len\n",
    "        encoded = [word_map.get(token, word_map['<unk>']) for token in tokens]\n",
    "\n",
    "    # Calculate correct padding length\n",
    "    padding_length = max_seq_len - len(encoded)\n",
    "\n",
    "    # Add padding if needed\n",
    "    if padding_length > 0:\n",
    "        encoded.extend([word_map['<pad>']] * padding_length)\n",
    "\n",
    "    return encoded"
   ],
   "id": "14a009d6686c1bde",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Process and Load Data",
   "id": "8ed4fad6ed616c9e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-27T23:33:09.286158Z",
     "start_time": "2025-04-27T23:32:58.455788Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Load and process data\n",
    "conversations, lines = load_conversations()\n",
    "lines_dict = create_lines_dict(lines)\n",
    "pairs = extract_pairs(conversations, lines_dict)\n",
    "word_map = build_vocab(pairs)"
   ],
   "id": "bbf6600f6c8223f5",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total pairs extracted: 221274\n",
      "Final vocabulary size: 41506\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Encode Conversation Pairs",
   "id": "95569d7d75facd51"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-27T23:33:10.600364Z",
     "start_time": "2025-04-27T23:33:09.315257Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Encode pairs with fixed function\n",
    "pairs_encoded = []\n",
    "for pair in pairs:\n",
    "    question = encode_sequence(pair[0], word_map, is_reply=False, max_seq_len=max_len)\n",
    "    answer = encode_sequence(pair[1], word_map, is_reply=True, max_seq_len=max_len)\n",
    "\n",
    "    # Validate lengths (important debugging check)\n",
    "    if len(question) != max_len or len(answer) != max_len:\n",
    "        print(f\"Warning: Inconsistent sequence length: Q:{len(question)}, A:{len(answer)}\")\n",
    "        continue\n",
    "\n",
    "    pairs_encoded.append([question, answer])"
   ],
   "id": "bef3b412d19ee8db",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Display Sample Data",
   "id": "7f203b9f3878e1d6"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-27T23:33:10.628207Z",
     "start_time": "2025-04-27T23:33:10.626614Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Add this after preprocessing a few examples\n",
    "sample_pairs = pairs[:5]\n",
    "print(\"\\nSample processed pairs:\")\n",
    "for pair in sample_pairs:\n",
    "    print(f\"Q: {' '.join(pair[0])}\")\n",
    "    print(f\"A: {' '.join(pair[1])}\")\n",
    "    print()"
   ],
   "id": "95934e9de876c5ee",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample processed pairs:\n",
      "Q: can we make this quick roxanne korrine and andrew barrett are having an\n",
      "A: well i thought we 'd start with pronunciation if that is okay with\n",
      "\n",
      "Q: well i thought we 'd start with pronunciation if that is okay with\n",
      "A: not the hacking and gagging and spitting part please\n",
      "\n",
      "Q: not the hacking and gagging and spitting part please\n",
      "A: okay then how 'bout we try out some french cuisine saturday night\n",
      "\n",
      "Q: you are asking me out that is so cute what is your name\n",
      "A: forget it\n",
      "\n",
      "Q: no no it is my fault we didn not have a proper introduction\n",
      "A: cameron\n",
      "\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Saved Processed Data",
   "id": "70bb3cad3f31bade"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-27T23:33:11.842120Z",
     "start_time": "2025-04-27T23:33:10.693587Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Save processed data\n",
    "with open('data/word_map_corpus.json', 'w') as f:\n",
    "    json.dump(word_map, f)\n",
    "with open('data/pairs_encoded.json', 'w') as f:\n",
    "    json.dump(pairs_encoded, f)\n",
    "\n",
    "print(f\"Vocabulary size: {len(word_map)}\")\n",
    "print(f\"Number of conversation pairs: {len(pairs_encoded)}\")"
   ],
   "id": "b141b64a45302f6b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size: 41506\n",
      "Number of conversation pairs: 221274\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Data Loading and Masking",
   "id": "9bf815b574c807f5"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-27T23:33:11.871838Z",
     "start_time": "2025-04-27T23:33:11.869730Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class ChatDataset(Dataset):\n",
    "    \"\"\"Dataset class for handling chat conversation pairs.\"\"\"\n",
    "\n",
    "    DEFAULT_DATA_PATH = 'data/pairs_encoded.json'\n",
    "\n",
    "    def __init__(self, data_path=DEFAULT_DATA_PATH):\n",
    "        \"\"\"Initialize dataset with conversation pairs.\n",
    "\n",
    "        Args:\n",
    "            data_path: Path to the JSON file containing encoded pairs\n",
    "        \"\"\"\n",
    "        try:\n",
    "            with open(data_path, 'r') as file:\n",
    "                self.pairs = json.load(file)\n",
    "            if not self.pairs:\n",
    "                raise ValueError(\"Empty dataset loaded\")\n",
    "        except FileNotFoundError:\n",
    "            raise FileNotFoundError(f\"Data file not found at: {data_path}\")\n",
    "        except json.JSONDecodeError:\n",
    "            raise ValueError(f\"Invalid JSON format in file: {data_path}\")\n",
    "\n",
    "        self.dataset_size = len(self.pairs)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"Get a conversation pair at the specified index.\"\"\"\n",
    "        pair = self.pairs[index]\n",
    "        question, reply = pair[0], pair[1]\n",
    "        return torch.LongTensor(question), torch.LongTensor(reply)\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"Return the total number of conversation pairs.\"\"\"\n",
    "        return self.dataset_size"
   ],
   "id": "aa8049febd0a6028",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-27T23:33:12.215126Z",
     "start_time": "2025-04-27T23:33:11.935035Z"
    }
   },
   "cell_type": "code",
   "source": "train_loader = DataLoader(ChatDataset(), batch_size=100, shuffle=True, pin_memory=True)",
   "id": "5c2a97081600f38a",
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-27T23:33:12.426584Z",
     "start_time": "2025-04-27T23:33:12.242187Z"
    }
   },
   "cell_type": "code",
   "source": "question, reply = next(iter(train_loader))",
   "id": "f87cb82d7070b8d3",
   "outputs": [],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-27T23:33:12.454803Z",
     "start_time": "2025-04-27T23:33:12.453142Z"
    }
   },
   "cell_type": "code",
   "source": "question.shape",
   "id": "b8611e194b852924",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([100, 13])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-27T23:33:12.522379Z",
     "start_time": "2025-04-27T23:33:12.520744Z"
    }
   },
   "cell_type": "code",
   "source": "reply.shape",
   "id": "6ad99270887bcae",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([100, 13])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-27T23:33:12.593018Z",
     "start_time": "2025-04-27T23:33:12.591226Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def create_masks(question, reply_input, reply_target):\n",
    "    def subsequent_mask(size):\n",
    "        mask = torch.triu(torch.ones(size, size)).transpose(0, 1).type(dtype=torch.uint8)\n",
    "        return mask.unsqueeze(0)\n",
    "\n",
    "    question_mask = (question != 0).to(device)\n",
    "    question_mask = question_mask.unsqueeze(1).unsqueeze(1)\n",
    "\n",
    "    reply_input_mask = reply_input != 0\n",
    "    reply_input_mask = reply_input_mask.unsqueeze(1)\n",
    "    reply_input_mask = reply_input_mask & subsequent_mask(reply_input.size(-1)).type_as(reply_input_mask.data)\n",
    "    # (batch_size, max_words, max_words)\n",
    "    reply_input_mask = reply_input_mask.unsqueeze(1)\n",
    "    reply_target_mask = reply_target != 0\n",
    "\n",
    "    return question_mask, reply_input_mask, reply_target_mask\n"
   ],
   "id": "88055d816f312bac",
   "outputs": [],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-27T23:33:12.659388Z",
     "start_time": "2025-04-27T23:33:12.656524Z"
    }
   },
   "cell_type": "code",
   "source": [
    "size = 5\n",
    "print(torch.triu(torch.ones(size, size)).transpose(0, 1))"
   ],
   "id": "ccc67b45fa364b9b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 0., 0., 0., 0.],\n",
      "        [1., 1., 0., 0., 0.],\n",
      "        [1., 1., 1., 0., 0.],\n",
      "        [1., 1., 1., 1., 0.],\n",
      "        [1., 1., 1., 1., 1.]])\n"
     ]
    }
   ],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-27T23:33:12.724771Z",
     "start_time": "2025-04-27T23:33:12.722935Z"
    }
   },
   "cell_type": "code",
   "source": "question[0] != 0",
   "id": "fe1687d4827f5668",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "        True])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 19
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Embeddings",
   "id": "2e67d8f9340f20be"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-27T23:33:12.792660Z",
     "start_time": "2025-04-27T23:33:12.790310Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class Embeddings(nn.Module):\n",
    "    DEFAULT_MAX_LENGTH = 50\n",
    "    DROPOUT_RATE = 0.1\n",
    "    POSITION_ENCODING_BASE = 10000\n",
    "\n",
    "    def __init__(self, vocab_size, embedding_dim, max_length=DEFAULT_MAX_LENGTH):\n",
    "        super(Embeddings, self).__init__()\n",
    "\n",
    "        self.vocab_size = vocab_size\n",
    "        self.embedding_dim = embedding_dim\n",
    "\n",
    "        self.dropout = nn.Dropout(self.DROPOUT_RATE)\n",
    "        self.token_embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "\n",
    "        # Create position encoding on CPU and register as buffer\n",
    "        # Using register_buffer is crucial as it handles device transfers properly\n",
    "        position_encoding = self._create_position_encoding(max_length, embedding_dim)\n",
    "        self.register_buffer('position_encoding', position_encoding)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Get sequence length from input\n",
    "        seq_len = x.size(1)\n",
    "\n",
    "        # Apply token embedding\n",
    "        embeddings = self.token_embedding(x) * math.sqrt(self.embedding_dim)\n",
    "\n",
    "        # Add positional encoding (slice to match sequence length)\n",
    "        embeddings = embeddings + self.position_encoding[:seq_len, :]\n",
    "\n",
    "        return self.dropout(embeddings)\n",
    "\n",
    "    def _create_position_encoding(self, max_length, embedding_dim):\n",
    "        \"\"\"Create position encoding matrix with sinusoidal patterns\"\"\"\n",
    "        position_encoding = torch.zeros(max_length, embedding_dim)\n",
    "\n",
    "        for pos in range(max_length):\n",
    "            for dim in range(0, embedding_dim, 2):\n",
    "                div_term = math.exp(dim * -math.log(self.POSITION_ENCODING_BASE) / embedding_dim)\n",
    "                position_encoding[pos, dim] = math.sin(pos * div_term)\n",
    "                if dim + 1 < embedding_dim:\n",
    "                    position_encoding[pos, dim + 1] = math.cos(pos * div_term)\n",
    "\n",
    "        return position_encoding"
   ],
   "id": "bc5bb901685bb713",
   "outputs": [],
   "execution_count": 20
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## MultiHead Attention Implementation Part 1",
   "id": "c1d9a820c332d338"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-27T23:33:12.859052Z",
     "start_time": "2025-04-27T23:33:12.856121Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class MultiHeadAttention(nn.Module):\n",
    "    \"\"\"Multi-head attention mechanism implementation.\n",
    "\n",
    "    Allows the model to jointly attend to information from different representation\n",
    "    subspaces at different positions.\n",
    "    \"\"\"\n",
    "    DROPOUT_RATE = 0.1\n",
    "    ATTENTION_MASK_FILL_VALUE = -1e9\n",
    "\n",
    "    def __init__(self, num_heads, d_model):\n",
    "        \"\"\"Initialize the multi-head attention layer.\n",
    "\n",
    "        Args:\n",
    "            num_heads: Number of attention heads\n",
    "            d_model: Dimension of the model\n",
    "        \"\"\"\n",
    "        super(MultiHeadAttention, self).__init__()\n",
    "        self._validate_dimensions(d_model, num_heads)\n",
    "\n",
    "        self.d_k = d_model // num_heads\n",
    "        self.num_heads = num_heads\n",
    "\n",
    "        # Linear layers for transformations\n",
    "        self.query_transform = nn.Linear(d_model, d_model)\n",
    "        self.key_transform = nn.Linear(d_model, d_model)\n",
    "        self.value_transform = nn.Linear(d_model, d_model)\n",
    "        self.output_transform = nn.Linear(d_model, d_model)\n",
    "\n",
    "        self.dropout = nn.Dropout(self.DROPOUT_RATE)\n",
    "\n",
    "    def _validate_dimensions(self, d_model, num_heads):\n",
    "        \"\"\"Validate that model dimensions are compatible with number of heads.\"\"\"\n",
    "        if d_model % num_heads != 0:\n",
    "            raise ValueError(\"d_model must be divisible by the number of heads\")\n",
    "\n",
    "    def _split_heads(self, x, batch_size):\n",
    "        \"\"\"Split the last dimension into (num_heads, d_k).\"\"\"\n",
    "        return x.view(batch_size, -1, self.num_heads, self.d_k).transpose(1, 2)\n",
    "\n",
    "    def _calculate_attention_scores(self, query, key):\n",
    "        \"\"\"Calculate raw attention scores.\"\"\"\n",
    "        return torch.matmul(query, key.transpose(-2, -1)) / math.sqrt(self.d_k)\n",
    "\n",
    "    def forward(self, query, key, value, mask):\n",
    "        \"\"\"\n",
    "        Compute multi-head attention.\n",
    "\n",
    "        Args:\n",
    "            query: Query tensor of shape (batch_size, seq_len, d_model)\n",
    "            key: Key tensor of shape (batch_size, seq_len, d_model)\n",
    "            value: Value tensor of shape (batch_size, seq_len, d_model)\n",
    "            mask: Attention mask of shape (batch_size, seq_len, seq_len)\n",
    "\n",
    "        Returns:\n",
    "            Output tensor of shape (batch_size, seq_len, d_model)\n",
    "        \"\"\"\n",
    "        batch_size = query.size(0)\n",
    "\n",
    "        # Linear transformations\n",
    "        query = self.query_transform(query)\n",
    "        key = self.key_transform(key)\n",
    "        value = self.value_transform(value)\n",
    "\n",
    "        # Split heads\n",
    "        query = self._split_heads(query, batch_size)\n",
    "        key = self._split_heads(key, batch_size)\n",
    "        value = self._split_heads(value, batch_size)\n",
    "\n",
    "        # Calculate attention scores\n",
    "        attention_scores = self._calculate_attention_scores(query, key)\n",
    "\n",
    "        # Apply mask and softmax\n",
    "        if mask is not None:\n",
    "            attention_scores = attention_scores.masked_fill(mask == 0, self.ATTENTION_MASK_FILL_VALUE)\n",
    "        attention_weights = self.dropout(F.softmax(attention_scores, dim=-1))\n",
    "\n",
    "        # Apply attention to values\n",
    "        output = torch.matmul(attention_weights, value)\n",
    "\n",
    "        # Combine heads and apply final transformation\n",
    "        output = output.transpose(1, 2).contiguous().view(batch_size, -1, self.num_heads * self.d_k)\n",
    "        return self.output_transform(output)"
   ],
   "id": "992f738cef2aa6fd",
   "outputs": [],
   "execution_count": 21
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-27T23:33:12.923615Z",
     "start_time": "2025-04-27T23:33:12.921811Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class FeedForward(nn.Module):\n",
    "    \"\"\"Feed-forward neural network module with two linear layers.\n",
    "\n",
    "    Implements a feed-forward network that consists of two linear transformations\n",
    "    with a ReLU activation and dropout in between.\n",
    "    \"\"\"\n",
    "\n",
    "    DROPOUT_RATE = 0.1\n",
    "\n",
    "    def __init__(self, input_dim, hidden_dim=2048) -> None:\n",
    "        \"\"\"Initialize the feed-forward network.\n",
    "\n",
    "        Args:\n",
    "            input_dim: Dimension of input features\n",
    "            hidden_dim: Dimension of hidden layer (default: 2048)\n",
    "        \"\"\"\n",
    "        super(FeedForward, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, hidden_dim)\n",
    "        self.fc2 = nn.Linear(hidden_dim, input_dim)\n",
    "        self.dropout = nn.Dropout(self.DROPOUT_RATE)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"Forward pass of the feed-forward network.\n",
    "\n",
    "        Args:\n",
    "            x: Input tensor\n",
    "\n",
    "        Returns:\n",
    "            Processed tensor after passing through the feed-forward layers\n",
    "        \"\"\"\n",
    "        hidden = F.relu(self.fc1(x))\n",
    "        output = self.fc2(self.dropout(hidden))\n",
    "        return output"
   ],
   "id": "f6defb41535c87d1",
   "outputs": [],
   "execution_count": 22
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-27T23:33:12.989622Z",
     "start_time": "2025-04-27T23:33:12.987318Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def visualize_attention_transpose():\n",
    "    # Create sample data\n",
    "    batch_size, seq_len, num_heads, head_dim = 1, 3, 2, 4\n",
    "    key = torch.ones(batch_size, num_heads, seq_len, head_dim)\n",
    "\n",
    "    print(\"Original key shape:\", key.shape)\n",
    "    print(\"Key before transpose:\\n\", key[0])  # Show first batch\n",
    "\n",
    "    key_transposed = key.transpose(-2, -1)\n",
    "    print(\"\\nTransposed key shape:\", key_transposed.shape)\n",
    "    print(\"Key after transpose:\\n\", key_transposed[0])  # Show first batch\n",
    "\n",
    "    return key, key_transposed\n",
    "\n",
    "# Run visualization\n",
    "key, key_t = visualize_attention_transpose()"
   ],
   "id": "93eec92bae13f738",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original key shape: torch.Size([1, 2, 3, 4])\n",
      "Key before transpose:\n",
      " tensor([[[1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1.]],\n",
      "\n",
      "        [[1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1.]]])\n",
      "\n",
      "Transposed key shape: torch.Size([1, 2, 4, 3])\n",
      "Key after transpose:\n",
      " tensor([[[1., 1., 1.],\n",
      "         [1., 1., 1.],\n",
      "         [1., 1., 1.],\n",
      "         [1., 1., 1.]],\n",
      "\n",
      "        [[1., 1., 1.],\n",
      "         [1., 1., 1.],\n",
      "         [1., 1., 1.],\n",
      "         [1., 1., 1.]]])\n"
     ]
    }
   ],
   "execution_count": 23
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Encoder Layer",
   "id": "67d20eebb39bd9a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-27T23:33:13.057274Z",
     "start_time": "2025-04-27T23:33:13.055286Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class EncoderLayer(nn.Module):\n",
    "    \"\"\"Encoder layer implementing self-attention and feed-forward mechanisms.\n",
    "\n",
    "    Contains self-attention layer, feed-forward network, layer normalization,\n",
    "    and dropout for regularization.\n",
    "    \"\"\"\n",
    "\n",
    "    DROPOUT_RATE = 0.1  # Default dropout rate\n",
    "\n",
    "    def __init__(self, d_model, num_heads):\n",
    "        \"\"\"Initialize encoder layer components.\n",
    "\n",
    "        Args:\n",
    "            d_model: Model dimension/size\n",
    "            num_heads: Number of attention heads\n",
    "        \"\"\"\n",
    "        super(EncoderLayer, self).__init__()\n",
    "        # Initialize attention mechanism\n",
    "        self.self_attention = MultiHeadAttention(num_heads, d_model)\n",
    "\n",
    "        # Initialize feed-forward network\n",
    "        self.feed_forward = FeedForward(d_model)\n",
    "\n",
    "        # Initialize layer normalization\n",
    "        self.layer_norm = nn.LayerNorm(d_model)\n",
    "\n",
    "        # Initialize dropout\n",
    "        self.dropout = nn.Dropout(self.DROPOUT_RATE)\n",
    "\n",
    "    def forward(self, embedding, mask):\n",
    "        \"\"\"Process input through encoder layer.\n",
    "\n",
    "        Args:\n",
    "            embedding: Input embeddings\n",
    "            mask: Attention mask\n",
    "\n",
    "        Returns:\n",
    "            Processed tensor after self-attention and feed-forward layers\n",
    "        \"\"\"\n",
    "        # Self-attention block\n",
    "        attention_output = self.self_attention(embedding, embedding, embedding, mask)\n",
    "        normalized_attention = self.layer_norm(embedding + attention_output)\n",
    "\n",
    "        # Feed-forward block\n",
    "        feed_forward_output = self.feed_forward(normalized_attention)\n",
    "        feed_forward_output = self.dropout(feed_forward_output)\n",
    "\n",
    "        # Final layer normalization\n",
    "        output = self.layer_norm(normalized_attention + feed_forward_output)\n",
    "\n",
    "        return output"
   ],
   "id": "bf7c6538906c71a",
   "outputs": [],
   "execution_count": 24
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Decoder Layer",
   "id": "983437fe12be9851"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-27T23:33:13.123552Z",
     "start_time": "2025-04-27T23:33:13.121464Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class DecoderLayer(nn.Module):\n",
    "    def __init__(self, d_model, num_heads):\n",
    "        super(DecoderLayer, self).__init__()\n",
    "        # Initialize layer components\n",
    "        self.layer_norm = nn.LayerNorm(d_model)\n",
    "        self.self_attention = MultiHeadAttention(num_heads, d_model)\n",
    "        self.encoder_attention = MultiHeadAttention(num_heads, d_model)\n",
    "        self.feed_forward = FeedForward(d_model)\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "\n",
    "    def forward(self, decoder_input, encoder_output, decoder_mask, encoder_mask):\n",
    "        # Self attention block\n",
    "        self_attention = self.self_attention(\n",
    "            decoder_input, decoder_input, decoder_input, encoder_mask\n",
    "        )\n",
    "        self_attention = self.dropout(self_attention)\n",
    "        self_attention = self.layer_norm(self_attention + decoder_input)\n",
    "\n",
    "        # Encoder-decoder attention block\n",
    "        enc_dec_attention = self.encoder_attention(\n",
    "            self_attention, encoder_output, encoder_output, decoder_mask\n",
    "        )\n",
    "        enc_dec_attention = self.dropout(enc_dec_attention)\n",
    "        enc_dec_attention = self.layer_norm(enc_dec_attention + self_attention)\n",
    "\n",
    "        # Feed forward block\n",
    "        output = self.feed_forward(enc_dec_attention)\n",
    "        output = self.dropout(output)\n",
    "        output = self.layer_norm(output + enc_dec_attention)\n",
    "\n",
    "        return output"
   ],
   "id": "41b8a6e1277b5d7",
   "outputs": [],
   "execution_count": 25
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Transformer",
   "id": "dc37b7397012c249"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-27T23:33:13.189133Z",
     "start_time": "2025-04-27T23:33:13.186861Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class Transformer(nn.Module):\n",
    "    def __init__(self, d_model, num_heads, num_layers, word_map, max_length=50):\n",
    "        super(Transformer, self).__init__()\n",
    "        self.d_model = d_model\n",
    "        self.vocab_size = len(word_map)\n",
    "        self.embedding = Embeddings(self.vocab_size, d_model, max_length)\n",
    "        self.encoder_layers = nn.ModuleList(\n",
    "            [EncoderLayer(d_model, num_heads) for _ in range(num_layers)]\n",
    "        )\n",
    "        self.decoder_layers = nn.ModuleList(\n",
    "            [DecoderLayer(d_model, num_heads) for _ in range(num_layers)]\n",
    "        )\n",
    "        self.logit = nn.Linear(d_model, self.vocab_size)\n",
    "\n",
    "    def encode(self, src_words, src_mask):\n",
    "        embedding = self.embedding(src_words)\n",
    "        for encoder_layer in self.encoder_layers:\n",
    "            embedding = encoder_layer(embedding, src_mask)\n",
    "        return embedding\n",
    "\n",
    "    def decode(self, tgt_words, tgt_mask, src_embeddings, src_mask):\n",
    "        embedding = self.embedding(tgt_words)\n",
    "        for decoder_layer in self.decoder_layers:\n",
    "            embedding = decoder_layer(embedding, src_embeddings,  src_mask, tgt_mask)\n",
    "        return embedding\n",
    "\n",
    "    def forward(self, src_words, src_mask, tgt_words, tgt_mask):\n",
    "        src_embeddings = self.encode(src_words, src_mask)\n",
    "        output = self.decode(tgt_words, tgt_mask, src_embeddings, src_mask)\n",
    "        return F.log_softmax(self.logit(output), dim=-1)"
   ],
   "id": "8c8cd0d122bb957e",
   "outputs": [],
   "execution_count": 26
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## AdamWarmup",
   "id": "f34791b65fc5691b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-27T23:33:13.254216Z",
     "start_time": "2025-04-27T23:33:13.252146Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class AdamOptimizerWithWarmup:\n",
    "    \"\"\"Implements Adam optimizer with warmup learning rate scheduling.\"\"\"\n",
    "\n",
    "    # Constants for learning rate calculation\n",
    "    MODEL_SIZE_POWER = -0.5\n",
    "    STEP_POWER = -0.5\n",
    "    WARMUP_POWER = -1.5\n",
    "\n",
    "    def __init__(self, model_size, warmup_steps, optimizer):\n",
    "        \"\"\"\n",
    "        Initialize the optimizer wrapper.\n",
    "\n",
    "        Args:\n",
    "            model_size: Size of the model (d_model in transformer architecture)\n",
    "            warmup_steps: Number of warmup steps\n",
    "            optimizer: Base optimizer instance\n",
    "        \"\"\"\n",
    "        self.model_size = model_size\n",
    "        self.warmup_steps = warmup_steps\n",
    "        self.optimizer = optimizer\n",
    "        self.current_step = 0\n",
    "        self.learning_rate = 0.0\n",
    "\n",
    "    def calculate_learning_rate(self):\n",
    "        \"\"\"Calculate the learning rate based on current step and warmup parameters.\"\"\"\n",
    "        model_factor = self.model_size ** self.MODEL_SIZE_POWER\n",
    "        step_factor = min(\n",
    "            self.current_step ** self.STEP_POWER,\n",
    "            self.current_step * self.warmup_steps ** self.WARMUP_POWER\n",
    "        )\n",
    "        return model_factor * step_factor\n",
    "\n",
    "    def _update_optimizer_learning_rate(self, lr):\n",
    "        \"\"\"Update the learning rate in optimizer's parameter groups.\"\"\"\n",
    "        for param_group in self.optimizer.param_groups:\n",
    "            param_group['lr'] = lr\n",
    "\n",
    "    def step(self):\n",
    "        \"\"\"Perform a single optimization step.\"\"\"\n",
    "        self.current_step += 1\n",
    "        self.learning_rate = self.calculate_learning_rate()\n",
    "        self._update_optimizer_learning_rate(self.learning_rate)\n",
    "        self.optimizer.step()"
   ],
   "id": "6fd1aed4beccb238",
   "outputs": [],
   "execution_count": 27
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-27T23:33:13.321873Z",
     "start_time": "2025-04-27T23:33:13.319370Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class LabelSmoothedLoss(nn.Module):\n",
    "    \"\"\"Loss function with label smoothing for more stable training.\"\"\"\n",
    "\n",
    "    def __init__(self, vocab_size, smoothing_factor):\n",
    "        \"\"\"\n",
    "        Initialize the label smoothed loss.\n",
    "\n",
    "        Args:\n",
    "            vocab_size: Size of the vocabulary\n",
    "            smoothing_factor: Label smoothing factor between 0 and 1\n",
    "        \"\"\"\n",
    "        super(LabelSmoothedLoss, self).__init__()\n",
    "        # Initialize with 'none' reduction to handle masking manually\n",
    "        self.criterion = nn.KLDivLoss(reduction='none')\n",
    "        self.vocab_size = vocab_size\n",
    "        self.smoothing_factor = smoothing_factor\n",
    "        self.confidence = 1.0 - smoothing_factor\n",
    "\n",
    "    def _prepare_inputs(self, predictions, target, mask):\n",
    "        \"\"\"\n",
    "        Reshape inputs to 2D tensors for processing.\n",
    "\n",
    "        Args:\n",
    "            predictions: Model output logits\n",
    "            target: Ground truth indices\n",
    "            mask: Mask for valid positions\n",
    "\n",
    "        Returns:\n",
    "            Tuple of reshaped tensors (predictions, target, mask)\n",
    "        \"\"\"\n",
    "        predictions = predictions.contiguous().view(-1, predictions.size(-1))\n",
    "        target = target.contiguous().view(-1)\n",
    "        mask = mask.contiguous().view(-1)\n",
    "        return predictions, target, mask\n",
    "\n",
    "    def _create_smoothed_labels(self, target, predictions):\n",
    "        \"\"\"\n",
    "        Create smoothed label distribution.\n",
    "\n",
    "        Args:\n",
    "            target: Ground truth indices\n",
    "            predictions: Model output logits to match shape\n",
    "\n",
    "        Returns:\n",
    "            Tensor of smoothed label distributions\n",
    "        \"\"\"\n",
    "        smoothed_labels = torch.zeros_like(predictions)\n",
    "        smoothing_value = self.smoothing_factor / (self.vocab_size - 1)\n",
    "        smoothed_labels.fill_(smoothing_value)\n",
    "        smoothed_labels.scatter_(1, target.unsqueeze(1), self.confidence)\n",
    "        return smoothed_labels\n",
    "\n",
    "    def forward(self, predictions, target, mask):\n",
    "        \"\"\"\n",
    "        Compute label-smoothed loss.\n",
    "\n",
    "        Args:\n",
    "            predictions: Network output (batch_size, seq_len, vocab_size)\n",
    "            target: Ground truth indices (batch_size, seq_len)\n",
    "            mask: Mask for valid positions (batch_size, seq_len)\n",
    "\n",
    "        Returns:\n",
    "            Scalar loss value\n",
    "        \"\"\"\n",
    "        predictions, target, mask = self._prepare_inputs(predictions, target, mask)\n",
    "        smoothed_labels = self._create_smoothed_labels(target, predictions)\n",
    "\n",
    "        # Apply log softmax and calculate KL divergence loss\n",
    "        loss = self.criterion(F.log_softmax(predictions, dim=-1), smoothed_labels)\n",
    "        masked_loss = (loss.sum(1) * mask).sum()\n",
    "        num_valid_elements = mask.sum().clamp(min=1)\n",
    "\n",
    "        return masked_loss / num_valid_elements"
   ],
   "id": "dece1dcdea95dbd9",
   "outputs": [],
   "execution_count": 28
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-27T23:33:13.386462Z",
     "start_time": "2025-04-27T23:33:13.385099Z"
    }
   },
   "cell_type": "code",
   "source": [
    "batch_size = 5\n",
    "max_words = 7\n",
    "vocab_size = 3\n",
    "prediction = torch.randn(batch_size, max_words, vocab_size)"
   ],
   "id": "4088dc6c7706b935",
   "outputs": [],
   "execution_count": 29
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-27T23:33:13.457216Z",
     "start_time": "2025-04-27T23:33:13.455505Z"
    }
   },
   "cell_type": "code",
   "source": [
    "prediction\n",
    "prediction.size()"
   ],
   "id": "1dee7530a7edfa6",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 7, 3])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 30
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-27T23:33:13.526126Z",
     "start_time": "2025-04-27T23:33:13.524824Z"
    }
   },
   "cell_type": "code",
   "source": "prediction = prediction.view(-1, prediction.shape[-1])",
   "id": "18e65f35ef790803",
   "outputs": [],
   "execution_count": 31
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-27T23:33:13.592902Z",
     "start_time": "2025-04-27T23:33:13.591284Z"
    }
   },
   "cell_type": "code",
   "source": "prediction.shape",
   "id": "242e7d72162222f9",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([35, 3])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 32
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-27T23:33:13.661294Z",
     "start_time": "2025-04-27T23:33:13.659912Z"
    }
   },
   "cell_type": "code",
   "source": "target = torch.LongTensor(batch_size * max_words).random_(0, vocab_size)",
   "id": "49ff4cf0e7b5a47",
   "outputs": [],
   "execution_count": 33
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-27T23:33:13.728337Z",
     "start_time": "2025-04-27T23:33:13.726717Z"
    }
   },
   "cell_type": "code",
   "source": [
    "target\n",
    "print(target.shape, target.view(-1))"
   ],
   "id": "eba59adf78e2e8f6",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([35]) tensor([0, 1, 1, 2, 2, 1, 1, 1, 2, 1, 1, 1, 1, 2, 0, 1, 2, 1, 0, 0, 0, 0, 1, 2,\n",
      "        2, 0, 1, 1, 0, 0, 1, 0, 2, 2, 2])\n"
     ]
    }
   ],
   "execution_count": 34
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-27T23:33:13.796967Z",
     "start_time": "2025-04-27T23:33:13.795658Z"
    }
   },
   "cell_type": "code",
   "source": "mask = target != 0",
   "id": "1ca6a3f14e265852",
   "outputs": [],
   "execution_count": 35
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-27T23:33:13.864469Z",
     "start_time": "2025-04-27T23:33:13.862816Z"
    }
   },
   "cell_type": "code",
   "source": "mask.shape",
   "id": "64b83bb4014220d",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([35])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 36
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-27T23:33:13.932687Z",
     "start_time": "2025-04-27T23:33:13.931375Z"
    }
   },
   "cell_type": "code",
   "source": "labels = prediction.data.clone()",
   "id": "3ed815349bccb8",
   "outputs": [],
   "execution_count": 37
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-27T23:33:13.975801Z",
     "start_time": "2025-04-27T23:33:13.973763Z"
    }
   },
   "cell_type": "code",
   "source": [
    "labels.shape\n",
    "labels.dim()"
   ],
   "id": "fc4a64a8599792bd",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 38
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-27T23:33:14.045851Z",
     "start_time": "2025-04-27T23:33:14.043907Z"
    }
   },
   "cell_type": "code",
   "source": "labels[0][0]",
   "id": "3d01c4c255d83052",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.7157)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 39
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-27T23:33:14.115158Z",
     "start_time": "2025-04-27T23:33:14.113100Z"
    }
   },
   "cell_type": "code",
   "source": "labels",
   "id": "ee059ce6ba6d70c4",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 7.1565e-01,  3.6509e-01, -5.3981e-01],\n",
       "        [-4.7762e-01,  6.5549e-01,  2.7337e-01],\n",
       "        [ 1.8979e-01, -5.5222e-01,  3.7167e-02],\n",
       "        [-2.0311e+00, -2.7439e-01, -2.9117e-01],\n",
       "        [-2.1653e-03,  8.4432e-01,  2.6970e-01],\n",
       "        [-6.8360e-01,  3.7101e-01, -1.4002e+00],\n",
       "        [-4.9654e-01,  1.2243e-01,  1.5639e+00],\n",
       "        [-1.5268e+00,  1.4914e-01,  6.4242e-01],\n",
       "        [-9.9305e-01, -7.0993e-01,  2.5749e-01],\n",
       "        [-7.8200e-01,  1.4948e+00,  2.0210e+00],\n",
       "        [-9.6901e-01, -1.1148e+00,  1.5794e-01],\n",
       "        [-2.4908e+00,  1.3834e-01,  3.1550e-01],\n",
       "        [ 2.7221e-01, -3.9186e-01,  1.2107e+00],\n",
       "        [ 5.8829e-01, -3.4528e-03, -5.9668e-01],\n",
       "        [ 2.9506e-01,  8.2074e-01, -6.2100e-01],\n",
       "        [ 4.8981e-01, -9.3641e-01, -8.8691e-01],\n",
       "        [ 2.6451e-01, -6.5536e-01,  2.6795e-01],\n",
       "        [-7.5342e-01, -5.1074e-01, -2.7636e-01],\n",
       "        [ 9.7846e-01, -1.2417e+00, -1.7655e-01],\n",
       "        [ 1.4046e+00,  6.9988e-01, -7.3460e-01],\n",
       "        [-4.7016e-01, -3.7457e-01,  3.9316e-01],\n",
       "        [-2.9717e-01,  2.8880e-02, -7.4062e-01],\n",
       "        [ 7.1176e-01,  9.5867e-03, -1.9553e-01],\n",
       "        [ 1.2315e+00,  6.5439e-01,  2.5486e+00],\n",
       "        [-9.5664e-01,  6.1098e-01, -1.7557e+00],\n",
       "        [ 2.0700e-01,  1.0491e+00,  2.6517e-02],\n",
       "        [ 1.8121e+00,  4.3334e-01, -8.5089e-01],\n",
       "        [ 3.4652e-01, -8.6715e-01, -1.9184e+00],\n",
       "        [ 7.3222e-01,  8.0338e-01,  3.4234e-01],\n",
       "        [ 1.1291e+00, -4.1106e-01, -8.9155e-01],\n",
       "        [ 6.5917e-01,  9.1101e-01,  1.1553e+00],\n",
       "        [ 1.0853e+00,  9.3042e-01, -7.1677e-01],\n",
       "        [-4.8083e-01,  3.3680e-01,  1.1174e+00],\n",
       "        [ 1.4210e+00, -6.8212e-02,  7.6256e-02],\n",
       "        [-2.0271e+00, -6.3204e-01, -1.6472e-01]])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 40
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-27T23:33:14.292408Z",
     "start_time": "2025-04-27T23:33:14.290211Z"
    }
   },
   "cell_type": "code",
   "source": "labels.fill_(0.3 / (vocab_size - 1))",
   "id": "b885a4a6c76e1a74",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.1500, 0.1500, 0.1500],\n",
       "        [0.1500, 0.1500, 0.1500],\n",
       "        [0.1500, 0.1500, 0.1500],\n",
       "        [0.1500, 0.1500, 0.1500],\n",
       "        [0.1500, 0.1500, 0.1500],\n",
       "        [0.1500, 0.1500, 0.1500],\n",
       "        [0.1500, 0.1500, 0.1500],\n",
       "        [0.1500, 0.1500, 0.1500],\n",
       "        [0.1500, 0.1500, 0.1500],\n",
       "        [0.1500, 0.1500, 0.1500],\n",
       "        [0.1500, 0.1500, 0.1500],\n",
       "        [0.1500, 0.1500, 0.1500],\n",
       "        [0.1500, 0.1500, 0.1500],\n",
       "        [0.1500, 0.1500, 0.1500],\n",
       "        [0.1500, 0.1500, 0.1500],\n",
       "        [0.1500, 0.1500, 0.1500],\n",
       "        [0.1500, 0.1500, 0.1500],\n",
       "        [0.1500, 0.1500, 0.1500],\n",
       "        [0.1500, 0.1500, 0.1500],\n",
       "        [0.1500, 0.1500, 0.1500],\n",
       "        [0.1500, 0.1500, 0.1500],\n",
       "        [0.1500, 0.1500, 0.1500],\n",
       "        [0.1500, 0.1500, 0.1500],\n",
       "        [0.1500, 0.1500, 0.1500],\n",
       "        [0.1500, 0.1500, 0.1500],\n",
       "        [0.1500, 0.1500, 0.1500],\n",
       "        [0.1500, 0.1500, 0.1500],\n",
       "        [0.1500, 0.1500, 0.1500],\n",
       "        [0.1500, 0.1500, 0.1500],\n",
       "        [0.1500, 0.1500, 0.1500],\n",
       "        [0.1500, 0.1500, 0.1500],\n",
       "        [0.1500, 0.1500, 0.1500],\n",
       "        [0.1500, 0.1500, 0.1500],\n",
       "        [0.1500, 0.1500, 0.1500],\n",
       "        [0.1500, 0.1500, 0.1500]])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 41
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-27T23:33:14.784751Z",
     "start_time": "2025-04-27T23:33:14.783503Z"
    }
   },
   "cell_type": "code",
   "source": "# labels.scatter(1, target.data.unsqueeze(1), 1 - 0.3)",
   "id": "4616bb9b3d9646b2",
   "outputs": [],
   "execution_count": 42
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-27T23:33:15.584326Z",
     "start_time": "2025-04-27T23:33:14.864041Z"
    }
   },
   "cell_type": "code",
   "source": [
    "d_model = 512 #512\n",
    "num_heads = 8 # 8\n",
    "num_layers = 6 # 6\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "epochs = 3 # 25\n",
    "\n",
    "with open(\"data/word_map_corpus.json\", \"r\") as f:\n",
    "    word_map = json.load(f)\n",
    "transformer = Transformer(d_model, num_heads, num_layers, word_map, 50).to(device)\n",
    "adam_optimizer = torch.optim.Adam(transformer.parameters(), lr=0, betas=(0.9, 0.98), eps=1e-9)\n",
    "transformer_optimizer = AdamOptimizerWithWarmup(d_model, 4000, adam_optimizer)\n",
    "criterion = LabelSmoothedLoss(vocab_size=len(word_map), smoothing_factor=0.1)"
   ],
   "id": "c160b82c8837e31",
   "outputs": [],
   "execution_count": 43
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Training Function",
   "id": "b9e38e68b4438652"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-27T23:33:15.632397Z",
     "start_time": "2025-04-27T23:33:15.630030Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def train(train_loader, transformer, criterion, epoch, batch_log_frequency=100):\n",
    "    \"\"\"Train the transformer model for one epoch.\n",
    "\n",
    "    Args:\n",
    "        train_loader: DataLoader containing training data\n",
    "        transformer: Transformer model to train\n",
    "        criterion: Loss function\n",
    "        epoch: Current epoch number\n",
    "        batch_log_frequency: How often to log batch progress (default: every 100 batches)\n",
    "    \"\"\"\n",
    "    transformer.train()\n",
    "    running_loss = 0\n",
    "    total_samples = 0\n",
    "\n",
    "    def process_batch(question, reply):\n",
    "        question = question.to(device)\n",
    "        reply = reply.to(device)\n",
    "        batch_size = question.shape[0]\n",
    "\n",
    "        # Split reply into input and target sequences\n",
    "        reply_input = reply[:, :-1]  # all tokens except last\n",
    "        reply_target = reply[:, 1:]  # all tokens except first\n",
    "\n",
    "        # Generate masks and compute model output\n",
    "        question_mask, reply_input_mask, reply_target_mask = create_masks(\n",
    "            question, reply_input, reply_target)\n",
    "        model_output = transformer(question, question_mask, reply_input, reply_input_mask)\n",
    "\n",
    "        # Compute loss\n",
    "        batch_loss = criterion(model_output, reply_target, reply_target_mask)\n",
    "        return batch_loss, batch_size\n",
    "\n",
    "    def log_progress(batch_idx, running_loss, total_samples):\n",
    "        avg_loss = running_loss / total_samples\n",
    "        print(f\"Epoch {epoch} | Batch {batch_idx} | Average Loss {avg_loss:.4f}\")\n",
    "\n",
    "    for batch_idx, (question, reply) in enumerate(train_loader):\n",
    "        # Process batch and compute loss\n",
    "        batch_loss, batch_size = process_batch(question, reply)\n",
    "\n",
    "        # Update running statistics\n",
    "        running_loss += batch_loss.item() * batch_size\n",
    "        total_samples += batch_size\n",
    "\n",
    "        # Backward pass and optimization\n",
    "        transformer_optimizer.optimizer.zero_grad()\n",
    "        batch_loss.backward()\n",
    "        transformer_optimizer.step()\n",
    "\n",
    "        # Log progress at specified intervals\n",
    "        if batch_idx % batch_log_frequency == 0:\n",
    "            log_progress(batch_idx, running_loss, total_samples)"
   ],
   "id": "63ac5f49b6c39d24",
   "outputs": [],
   "execution_count": 44
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-27T23:33:15.677217Z",
     "start_time": "2025-04-27T23:33:15.674104Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def create_target_mask(size):\n",
    "    \"\"\"\n",
    "    Creates a triangular (causal) mask for decoder self-attention.\n",
    "    Args:\n",
    "        size: Size of the target sequence\n",
    "    Returns:\n",
    "        Mask tensor of shape (1, 1, size, size)\n",
    "    \"\"\"\n",
    "    # Create a triangular mask (lower triangular matrix of 1's)\n",
    "    mask = torch.triu(torch.ones(size, size), diagonal=1).bool()\n",
    "    # Reshape mask to (1, 1, size, size) for broadcasting\n",
    "    mask = mask.unsqueeze(0).unsqueeze(0)\n",
    "    return mask.to(device)\n",
    "\n",
    "def evaluate(transformer, question, question_mask, max_len=50,\n",
    "                         temperature=0.7, top_k=50):\n",
    "    \"\"\"\n",
    "    Generate response using temperature and top-k sampling.\n",
    "\n",
    "    Args:\n",
    "        transformer: The transformer model\n",
    "        question: Input question tensor\n",
    "        question_mask: Mask for the input question\n",
    "        max_len: Maximum length of generated sequence\n",
    "        temperature: Temperature for sampling (lower = more conservative)\n",
    "        top_k: Number of top tokens to consider for sampling\n",
    "\n",
    "    Returns:\n",
    "        Generated sequence of token indices\n",
    "    \"\"\"\n",
    "    transformer.eval()\n",
    "    rev_word_map = {v: k for k, v in word_map.items()}\n",
    "\n",
    "    # Encode the input question\n",
    "    encoded = transformer.encode(question, question_mask)\n",
    "\n",
    "    # Initialize with start token\n",
    "    words = torch.LongTensor([[word_map['<start>']]]).to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for _ in range(max_len - 1):\n",
    "            # Create mask for the current sequence\n",
    "            target_mask = create_target_mask(words.size(1))\n",
    "\n",
    "            # Generate next token probabilities\n",
    "            decoded = transformer.decode(words, target_mask, encoded, question_mask)\n",
    "            predictions = transformer.logit(decoded[:, -1])\n",
    "\n",
    "            # Apply temperature\n",
    "            predictions = predictions / temperature\n",
    "\n",
    "            # Apply top-k filtering\n",
    "            values, indices = predictions[0].topk(top_k)\n",
    "            predictions[0] = torch.full_like(predictions[0], float('-inf'))\n",
    "            predictions[0, indices] = values\n",
    "\n",
    "            # Sample from the filtered distribution\n",
    "            probabilities = F.softmax(predictions, dim=-1)\n",
    "            next_word = torch.multinomial(probabilities, 1)\n",
    "\n",
    "            # Stop if end token is generated\n",
    "            if next_word.item() == word_map['<end>']:\n",
    "                break\n",
    "\n",
    "            # Add the new token to the sequence\n",
    "            words = torch.cat([words, next_word.view(1, 1)], dim=1)\n",
    "\n",
    "    # Convert to text\n",
    "    generated_tokens = words.squeeze(0).tolist()\n",
    "    generated_words = [rev_word_map[idx] for idx in generated_tokens\n",
    "                      if idx not in {word_map['<start>'], word_map['<end>'], word_map['<pad>']}]\n",
    "\n",
    "    return ' '.join(generated_words)"
   ],
   "id": "e197c6e07b97aabb",
   "outputs": [],
   "execution_count": 45
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-27T23:33:15.742271Z",
     "start_time": "2025-04-27T23:33:15.739171Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def beam_search_evaluate(transformer, question, question_mask, beam_size=5, max_len=50):\n",
    "    \"\"\"\n",
    "    Generate response using beam search.\n",
    "\n",
    "    Args:\n",
    "        transformer: The transformer model\n",
    "        question: Input question tensor\n",
    "        question_mask: Mask for the input question\n",
    "        beam_size: Number of beams to maintain\n",
    "        max_len: Maximum length of generated sequence\n",
    "    \"\"\"\n",
    "    transformer.eval()\n",
    "    rev_word_map = {v: k for k, v in word_map.items()}\n",
    "\n",
    "    # Encode the input question\n",
    "    encoded = transformer.encode(question, question_mask)\n",
    "\n",
    "    # Initialize beams with start token\n",
    "    # Each beam is (sequence, score)\n",
    "    beams = [(torch.LongTensor([[word_map['<start>']]]).to(device), 0.0)]\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for _ in range(max_len-1):\n",
    "            candidates = []\n",
    "\n",
    "            # Expand each current beam\n",
    "            for sequence, score in beams:\n",
    "                # Skip if sequence is already completed\n",
    "                if sequence[0][-1].item() == word_map['<end>']:\n",
    "                    candidates.append((sequence, score))\n",
    "                    continue\n",
    "\n",
    "                # Create mask for the current sequence\n",
    "                target_mask = create_target_mask(sequence.size(1))\n",
    "\n",
    "                # Generate next token probabilities\n",
    "                decoded = transformer.decode(sequence, target_mask, encoded, question_mask)\n",
    "                logits = transformer.logit(decoded[:, -1])\n",
    "                log_probs = F.log_softmax(logits, dim=-1)\n",
    "\n",
    "                # Get top k candidates for each beam\n",
    "                values, indices = log_probs[0].topk(beam_size)\n",
    "\n",
    "                # Create new candidates\n",
    "                for token, token_score in zip(indices, values):\n",
    "                    new_sequence = torch.cat([sequence,\n",
    "                        torch.LongTensor([[token]]).to(device)], dim=1)\n",
    "                    # Add scores in log space\n",
    "                    new_score = score + token_score.item()\n",
    "                    candidates.append((new_sequence, new_score))\n",
    "\n",
    "            # Select top beam_size candidates\n",
    "            # Sort by score and normalize by length to prevent bias towards shorter sequences\n",
    "            candidates = [(seq, score/len(seq[0])) for seq, score in candidates]\n",
    "            beams = sorted(candidates, key=lambda x: x[1], reverse=True)[:beam_size]\n",
    "\n",
    "            # Stop if all beams end with <end> token\n",
    "            if all(b[0][0][-1].item() == word_map['<end>'] for b in beams):\n",
    "                break\n",
    "\n",
    "    # Return the highest scoring sequence\n",
    "    best_sequence = beams[0][0]\n",
    "    generated_tokens = best_sequence.squeeze(0).tolist()\n",
    "    generated_words = [rev_word_map[idx] for idx in generated_tokens\n",
    "                      if idx not in {word_map['<start>'], word_map['<end>'], word_map['<pad>']}]\n",
    "\n",
    "    return ' '.join(generated_words)"
   ],
   "id": "88328bfb7ebd6457",
   "outputs": [],
   "execution_count": 46
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-27T23:40:34.870911Z",
     "start_time": "2025-04-27T23:33:15.804805Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for epoch in range(epochs):\n",
    "    train(train_loader, transformer, criterion, epoch)\n",
    "    state = {\n",
    "        'epoch': epoch,\n",
    "        'transformer_state_dict': transformer.state_dict(),\n",
    "        'optimizer_state_dict': transformer_optimizer.optimizer.state_dict()\n",
    "    }\n",
    "    torch.save(state, f\"models/checkpoint_{epoch}.tar\")"
   ],
   "id": "b103ef0a6651a3e3",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 | Batch 0 | Average Loss 9.3935\n",
      "Epoch 0 | Batch 100 | Average Loss 8.2095\n",
      "Epoch 0 | Batch 200 | Average Loss 7.4553\n",
      "Epoch 0 | Batch 300 | Average Loss 6.7704\n",
      "Epoch 0 | Batch 400 | Average Loss 6.2916\n",
      "Epoch 0 | Batch 500 | Average Loss 5.9735\n",
      "Epoch 0 | Batch 600 | Average Loss 5.7395\n",
      "Epoch 0 | Batch 700 | Average Loss 5.5629\n",
      "Epoch 0 | Batch 800 | Average Loss 5.4223\n",
      "Epoch 0 | Batch 900 | Average Loss 5.3084\n",
      "Epoch 0 | Batch 1000 | Average Loss 5.2095\n",
      "Epoch 0 | Batch 1100 | Average Loss 5.1265\n",
      "Epoch 0 | Batch 1200 | Average Loss 5.0541\n",
      "Epoch 0 | Batch 1300 | Average Loss 4.9939\n",
      "Epoch 0 | Batch 1400 | Average Loss 4.9393\n",
      "Epoch 0 | Batch 1500 | Average Loss 4.8926\n",
      "Epoch 0 | Batch 1600 | Average Loss 4.8510\n",
      "Epoch 0 | Batch 1700 | Average Loss 4.8123\n",
      "Epoch 0 | Batch 1800 | Average Loss 4.7782\n",
      "Epoch 0 | Batch 1900 | Average Loss 4.7473\n",
      "Epoch 0 | Batch 2000 | Average Loss 4.7183\n",
      "Epoch 0 | Batch 2100 | Average Loss 4.6911\n",
      "Epoch 0 | Batch 2200 | Average Loss 4.6665\n",
      "Epoch 1 | Batch 0 | Average Loss 4.2452\n",
      "Epoch 1 | Batch 100 | Average Loss 4.1093\n",
      "Epoch 1 | Batch 200 | Average Loss 4.1165\n",
      "Epoch 1 | Batch 300 | Average Loss 4.1146\n",
      "Epoch 1 | Batch 400 | Average Loss 4.1170\n",
      "Epoch 1 | Batch 500 | Average Loss 4.1146\n",
      "Epoch 1 | Batch 600 | Average Loss 4.1139\n",
      "Epoch 1 | Batch 700 | Average Loss 4.1149\n",
      "Epoch 1 | Batch 800 | Average Loss 4.1120\n",
      "Epoch 1 | Batch 900 | Average Loss 4.1104\n",
      "Epoch 1 | Batch 1000 | Average Loss 4.1128\n",
      "Epoch 1 | Batch 1100 | Average Loss 4.1135\n",
      "Epoch 1 | Batch 1200 | Average Loss 4.1132\n",
      "Epoch 1 | Batch 1300 | Average Loss 4.1130\n",
      "Epoch 1 | Batch 1400 | Average Loss 4.1131\n",
      "Epoch 1 | Batch 1500 | Average Loss 4.1129\n",
      "Epoch 1 | Batch 1600 | Average Loss 4.1140\n",
      "Epoch 1 | Batch 1700 | Average Loss 4.1133\n",
      "Epoch 1 | Batch 1800 | Average Loss 4.1134\n",
      "Epoch 1 | Batch 1900 | Average Loss 4.1136\n",
      "Epoch 1 | Batch 2000 | Average Loss 4.1137\n",
      "Epoch 1 | Batch 2100 | Average Loss 4.1131\n",
      "Epoch 1 | Batch 2200 | Average Loss 4.1125\n",
      "Epoch 2 | Batch 0 | Average Loss 3.9234\n",
      "Epoch 2 | Batch 100 | Average Loss 4.0468\n",
      "Epoch 2 | Batch 200 | Average Loss 4.0425\n",
      "Epoch 2 | Batch 300 | Average Loss 4.0451\n",
      "Epoch 2 | Batch 400 | Average Loss 4.0476\n",
      "Epoch 2 | Batch 500 | Average Loss 4.0496\n",
      "Epoch 2 | Batch 600 | Average Loss 4.0520\n",
      "Epoch 2 | Batch 700 | Average Loss 4.0520\n",
      "Epoch 2 | Batch 800 | Average Loss 4.0544\n",
      "Epoch 2 | Batch 900 | Average Loss 4.0542\n",
      "Epoch 2 | Batch 1000 | Average Loss 4.0543\n",
      "Epoch 2 | Batch 1100 | Average Loss 4.0527\n",
      "Epoch 2 | Batch 1200 | Average Loss 4.0517\n",
      "Epoch 2 | Batch 1300 | Average Loss 4.0517\n",
      "Epoch 2 | Batch 1400 | Average Loss 4.0506\n",
      "Epoch 2 | Batch 1500 | Average Loss 4.0496\n",
      "Epoch 2 | Batch 1600 | Average Loss 4.0495\n",
      "Epoch 2 | Batch 1700 | Average Loss 4.0484\n",
      "Epoch 2 | Batch 1800 | Average Loss 4.0478\n",
      "Epoch 2 | Batch 1900 | Average Loss 4.0474\n",
      "Epoch 2 | Batch 2000 | Average Loss 4.0463\n",
      "Epoch 2 | Batch 2100 | Average Loss 4.0459\n",
      "Epoch 2 | Batch 2200 | Average Loss 4.0457\n"
     ]
    }
   ],
   "execution_count": 47
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-27T23:40:35.532309Z",
     "start_time": "2025-04-27T23:40:34.901062Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Add both custom classes and the built-in set type\n",
    "import torch.serialization\n",
    "\n",
    "# Add built-in set type\n",
    "torch.serialization.add_safe_globals([set])\n",
    "\n",
    "# Add all custom model classes\n",
    "torch.serialization.add_safe_globals([\n",
    "    Transformer,\n",
    "    MultiHeadAttention,\n",
    "    EncoderLayer,\n",
    "    DecoderLayer,\n",
    "    Embeddings,\n",
    "    FeedForward,\n",
    "    AdamOptimizerWithWarmup,\n",
    "    LabelSmoothedLoss\n",
    "])\n",
    "\n",
    "# Now try loading the checkpoint\n",
    "checkpoint = torch.load(\"models/checkpoint_2.tar\", weights_only=True)\n",
    "\n",
    "# Create new model instance and load state dict\n",
    "transformer = Transformer(d_model, num_heads, num_layers, word_map).to(device)\n",
    "transformer.load_state_dict(checkpoint['transformer_state_dict'])"
   ],
   "id": "83b9b390438f7066",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 48
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-27T23:40:35.561934Z",
     "start_time": "2025-04-27T23:40:35.559936Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "# Function to chat with the model using the new sampling method\n",
    "def chat_with_model(transformer, word_map, max_len=50, temperature=0.7, top_k=50):\n",
    "    \"\"\"\n",
    "    Interactive chat function with the model.\n",
    "\n",
    "    Args:\n",
    "        transformer: The transformer model\n",
    "        word_map: Dictionary mapping words to indices\n",
    "        max_len: Maximum length of generated response\n",
    "        temperature: Temperature for sampling\n",
    "        top_k: Number of top tokens to consider for sampling\n",
    "    \"\"\"\n",
    "    transformer.eval()\n",
    "    print(\"Chat started (type 'quit' to exit)\")\n",
    "\n",
    "    while True:\n",
    "        # Get user input\n",
    "        user_input = input(\"You: \")\n",
    "        if user_input.lower() in ['quit', 'exit']:\n",
    "            break\n",
    "\n",
    "        # Preprocess input\n",
    "        tokens = word_tokenize(user_input.lower())\n",
    "        encoded = [word_map.get(token, word_map['<unk>']) for token in tokens]\n",
    "\n",
    "        # Prepare input tensors\n",
    "        question = torch.LongTensor([encoded]).to(device)\n",
    "        question_mask = (question != 0).unsqueeze(1).unsqueeze(1).to(device)\n",
    "\n",
    "        # Generate response\n",
    "        response = evaluate(transformer, question, question_mask,\n",
    "                                       max_len=max_len,\n",
    "                                       temperature=temperature,\n",
    "                                       top_k=top_k)\n",
    "\n",
    "        print(\"Bot:\", response)"
   ],
   "id": "cd5484a48d07c79f",
   "outputs": [],
   "execution_count": 49
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-27T23:51:03.300547Z",
     "start_time": "2025-04-27T23:40:35.626096Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# After training the model\n",
    "print(\"Starting chat with improved generation...\")\n",
    "chat_with_model(transformer, word_map,\n",
    "                max_len=50,        # Maximum response length\n",
    "                temperature=0.6,   # Lower = more focused, higher = more creative\n",
    "                top_k=10)         # Number of top tokens to consider"
   ],
   "id": "a3d2291e6b7e38b8",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting chat with improved generation...\n",
      "Chat started (type 'quit' to exit)\n",
      "Bot: i\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "Interrupted by user",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[50], line 3\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;66;03m# After training the model\u001B[39;00m\n\u001B[1;32m      2\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mStarting chat with improved generation...\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m----> 3\u001B[0m \u001B[43mchat_with_model\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtransformer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mword_map\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m      4\u001B[0m \u001B[43m                \u001B[49m\u001B[43mmax_len\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m50\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m        \u001B[49m\u001B[38;5;66;43;03m# Maximum response length\u001B[39;49;00m\n\u001B[1;32m      5\u001B[0m \u001B[43m                \u001B[49m\u001B[43mtemperature\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m0.6\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m   \u001B[49m\u001B[38;5;66;43;03m# Lower = more focused, higher = more creative\u001B[39;49;00m\n\u001B[1;32m      6\u001B[0m \u001B[43m                \u001B[49m\u001B[43mtop_k\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m10\u001B[39;49m\u001B[43m)\u001B[49m         \u001B[38;5;66;03m# Number of top tokens to consider\u001B[39;00m\n",
      "Cell \u001B[0;32mIn[49], line 18\u001B[0m, in \u001B[0;36mchat_with_model\u001B[0;34m(transformer, word_map, max_len, temperature, top_k)\u001B[0m\n\u001B[1;32m     14\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mChat started (type \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mquit\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m to exit)\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m     16\u001B[0m \u001B[38;5;28;01mwhile\u001B[39;00m \u001B[38;5;28;01mTrue\u001B[39;00m:\n\u001B[1;32m     17\u001B[0m     \u001B[38;5;66;03m# Get user input\u001B[39;00m\n\u001B[0;32m---> 18\u001B[0m     user_input \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43minput\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mYou: \u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m     19\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m user_input\u001B[38;5;241m.\u001B[39mlower() \u001B[38;5;129;01min\u001B[39;00m [\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mquit\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mexit\u001B[39m\u001B[38;5;124m'\u001B[39m]:\n\u001B[1;32m     20\u001B[0m         \u001B[38;5;28;01mbreak\u001B[39;00m\n",
      "File \u001B[0;32m~/.local/lib/python3.12/site-packages/ipykernel/kernelbase.py:1282\u001B[0m, in \u001B[0;36mKernel.raw_input\u001B[0;34m(self, prompt)\u001B[0m\n\u001B[1;32m   1280\u001B[0m     msg \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mraw_input was called, but this frontend does not support input requests.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m   1281\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m StdinNotImplementedError(msg)\n\u001B[0;32m-> 1282\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_input_request\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   1283\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43mstr\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mprompt\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1284\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_parent_ident\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mshell\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1285\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_parent\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mshell\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1286\u001B[0m \u001B[43m    \u001B[49m\u001B[43mpassword\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m   1287\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/.local/lib/python3.12/site-packages/ipykernel/kernelbase.py:1325\u001B[0m, in \u001B[0;36mKernel._input_request\u001B[0;34m(self, prompt, ident, parent, password)\u001B[0m\n\u001B[1;32m   1322\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mKeyboardInterrupt\u001B[39;00m:\n\u001B[1;32m   1323\u001B[0m     \u001B[38;5;66;03m# re-raise KeyboardInterrupt, to truncate traceback\u001B[39;00m\n\u001B[1;32m   1324\u001B[0m     msg \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mInterrupted by user\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m-> 1325\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mKeyboardInterrupt\u001B[39;00m(msg) \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m   1326\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m:\n\u001B[1;32m   1327\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlog\u001B[38;5;241m.\u001B[39mwarning(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mInvalid Message:\u001B[39m\u001B[38;5;124m\"\u001B[39m, exc_info\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: Interrupted by user"
     ]
    }
   ],
   "execution_count": 50
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def chat_with_model(transformer, word_map, max_len=50, beam_size=5):\n",
    "    transformer.eval()\n",
    "    print(\"Chat started (type 'quit' to exit)\")\n",
    "\n",
    "    while True:\n",
    "        user_input = input(\"You: \")\n",
    "        if user_input.lower() in ['quit', 'exit']:\n",
    "            break\n",
    "\n",
    "        # Preprocess input\n",
    "        tokens = word_tokenize(user_input.lower())\n",
    "        encoded = [word_map.get(token, word_map['<unk>']) for token in tokens]\n",
    "\n",
    "        # Prepare input tensors\n",
    "        question = torch.LongTensor([encoded]).to(device)\n",
    "        question_mask = (question != 0).unsqueeze(1).unsqueeze(1).to(device)\n",
    "\n",
    "        # Generate response using beam search\n",
    "        response = beam_search_evaluate(transformer, question, question_mask,\n",
    "                                     beam_size=beam_size, max_len=max_len)\n",
    "        print(\"Bot:\", response)\n",
    "\n",
    "# Try with different beam sizes\n",
    "chat_with_model(transformer, word_map, beam_size=5)  # Start with beam_size=5"
   ],
   "id": "ebd928165e8dc08a"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
