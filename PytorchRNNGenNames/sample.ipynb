{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# NLP From Scratch: Generating Names with a Character-Level RNN",
   "id": "8a77807f92f26ee"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-10T23:44:00.714459Z",
     "start_time": "2025-03-10T23:44:00.711670Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "import zipfile\n",
    "import requests\n",
    "\n",
    "data_dir = 'data/data/names/'\n",
    "zip_path = 'data/data.zip'\n",
    "url = 'https://download.pytorch.org/tutorial/data.zip'\n",
    "\n",
    "try:\n",
    "    # Check if the target directory already exists\n",
    "    if not os.path.exists(data_dir):\n",
    "        # Ensure the parent directory exists\n",
    "        os.makedirs(os.path.dirname(zip_path), exist_ok=True)\n",
    "\n",
    "        # Download the file\n",
    "        print(\"Downloading data...\")\n",
    "        response = requests.get(url, stream=True)\n",
    "        if response.status_code == 200:\n",
    "            with open(zip_path, 'wb') as file:\n",
    "                file.write(response.content)  # Write the content of the request to a file\n",
    "        else:\n",
    "            raise Exception(f\"Failed to download file from {url}, status code: {response.status_code}\")\n",
    "\n",
    "        # Extract the zip file\n",
    "        print(\"Extracting data...\")\n",
    "        with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
    "            zip_ref.extractall('data')\n",
    "\n",
    "        print(\"Data was successfully downloaded and extracted.\")\n",
    "\n",
    "        # Clean up the zip file\n",
    "        os.remove(zip_path)\n",
    "    else:\n",
    "        print(\"Data already exists. No download needed.\")\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")"
   ],
   "id": "fbc121e30a2defb3",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data already exists. No download needed.\n"
     ]
    }
   ],
   "execution_count": 461
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-10T23:44:00.739299Z",
     "start_time": "2025-03-10T23:44:00.723510Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from io import open\n",
    "import glob\n",
    "import os\n",
    "import unicodedata\n",
    "import string\n",
    "\n",
    "all_letters = string.ascii_letters + \" .,;'-\"\n",
    "n_letters = len(all_letters) + 1 # Plus EOS marker\n",
    "\n",
    "def findFiles(path): return glob.glob(path)\n",
    "\n",
    "# Turn a Unicode string to plain ASCII, thanks to https://stackoverflow.com/a/518232/2809427\n",
    "def unicodeToAscii(s):\n",
    "    return ''.join(\n",
    "        c for c in unicodedata.normalize('NFD', s)\n",
    "        if unicodedata.category(c) != 'Mn'\n",
    "        and c in all_letters\n",
    "    )\n",
    "\n",
    "# Read a file and split into lines\n",
    "def readLines(filename):\n",
    "    with open(filename, encoding='utf-8') as some_file:\n",
    "        return [unicodeToAscii(line.strip()) for line in some_file]\n",
    "\n",
    "# Build the category_lines dictionary, a list of lines per category\n",
    "category_lines = {}\n",
    "all_categories = []\n",
    "for filename in findFiles('data/data/names/*.txt'):\n",
    "    category = os.path.splitext(os.path.basename(filename))[0]\n",
    "    all_categories.append(category)\n",
    "    lines = readLines(filename)\n",
    "    category_lines[category] = lines\n",
    "\n",
    "n_categories = len(all_categories)\n",
    "\n",
    "if n_categories == 0:\n",
    "    raise RuntimeError(\n",
    "        \"Data not found. Please ensure the following steps are completed:\\n\"\n",
    "        \"- Verify that the directory 'data/data/names/' exists and contains the required files.\\n\"\n",
    "        \"- If the directory or files are missing, download the data from 'https://download.pytorch.org/tutorial/data.zip'.\\n\"\n",
    "        \"- Extract the contents of the zip file into the current working directory.\"\n",
    "    )\n",
    "\n",
    "print('# categories:', n_categories, all_categories)\n",
    "print(unicodeToAscii(\"O'Néàl\"))\n",
    "all_characters = set"
   ],
   "id": "6892584d38a772d0",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# categories: 18 ['Spanish', 'Vietnamese', 'Italian', 'Russian', 'Greek', 'French', 'Scottish', 'Japanese', 'Arabic', 'Portuguese', 'Polish', 'Dutch', 'Czech', 'English', 'Irish', 'German', 'Korean', 'Chinese']\n",
      "O'Neal\n"
     ]
    }
   ],
   "execution_count": 462
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Creating the Network",
   "id": "95c643275360302c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-10T23:44:00.772403Z",
     "start_time": "2025-03-10T23:44:00.769957Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "class RNN(nn.Module):\n",
    "    \"\"\"\n",
    "    A Recurrent Neural Network (RNN) designed for generating names character by character.\n",
    "    It takes as input a category (e.g., a language), a character, and a hidden state,\n",
    "    and predicts the next character in the sequence while updating its hidden state.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(RNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        # Linear layer to combine category, input, and previous hidden state into the new hidden state.\n",
    "        # i2h stands for \"input to hidden\"; it transforms the combined input into the next hidden state.\n",
    "        self.i2h = nn.Linear(n_categories + input_size + hidden_size, hidden_size)\n",
    "        # Linear layer to transform the combined category, input, and hidden state into the raw output (input to output)\n",
    "        self.i2o = nn.Linear(n_categories + input_size + hidden_size, output_size)\n",
    "        # Linear layer to refine the output using the hidden state and previous output\n",
    "        self.o2o = nn.Linear(hidden_size + output_size, output_size)\n",
    "        # Dropout for regularization to prevent overfitting\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "        # LogSoftmax activation for generating log probabilities of the output classes\n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "\n",
    "    def forward(self, category, input, hidden):\n",
    "        # Combine category, input, and previous hidden state into a single tensor\n",
    "        input_combined = torch.cat((category, input, hidden), 1)\n",
    "        # Compute the new hidden state\n",
    "        hidden = self.i2h(input_combined)\n",
    "        # Generate raw output logits from the input and category\n",
    "        output = self.i2o(input_combined)\n",
    "        # Combine hidden state and raw output for refinement\n",
    "        output_combined = torch.cat((hidden, output), 1)\n",
    "        # Apply the final linear transformation, dropout, and softmax\n",
    "        output = self.o2o(output_combined)\n",
    "        output = self.dropout(output)\n",
    "        output = self.softmax(output)\n",
    "        return output, hidden\n",
    "\n",
    "    def initHidden(self):\n",
    "        # Initialize the hidden state tensor with zeros\n",
    "        return torch.zeros(1, self.hidden_size)"
   ],
   "id": "26963a8f20dd499e",
   "outputs": [],
   "execution_count": 463
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-10T23:44:00.815361Z",
     "start_time": "2025-03-10T23:44:00.813736Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import random\n",
    "\n",
    "# Random item from a list\n",
    "def randomChoice(l):\n",
    "    return l[random.randint(0, len(l) - 1)]\n",
    "\n",
    "# Get a random category and random line from that category\n",
    "def randomTrainingPair():\n",
    "    category = randomChoice(all_categories)\n",
    "    line = randomChoice(category_lines[category])\n",
    "    return category, line"
   ],
   "id": "89df604217af0a14",
   "outputs": [],
   "execution_count": 464
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-10T23:44:00.860580Z",
     "start_time": "2025-03-10T23:44:00.858243Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Function to generate a one-hot encoded tensor representing the category.\n",
    "# The function indexes the category position in `all_categories` and sets the corresponding position in the tensor to 1.\n",
    "def categoryTensor(category):\n",
    "    li = all_categories.index(category)\n",
    "    tensor = torch.zeros(1, n_categories)\n",
    "    tensor[0][li] = 1\n",
    "    return tensor\n",
    "\n",
    "\n",
    "# Function to generate a one-hot encoded tensor for the input string (line).\n",
    "# Each character in the input string is represented as a one-hot vector, and all such vectors are stacked together.\n",
    "def inputTensor(line):\n",
    "    tensor = torch.zeros(len(line), 1, n_letters)\n",
    "    for li in range(len(line)):\n",
    "        letter = line[li]\n",
    "        tensor[li][0][all_letters.find(letter)] = 1\n",
    "    return tensor\n",
    "\n",
    "\n",
    "# Function to create a LongTensor representing the target output sequence.\n",
    "# Each character is encoded as its index in `all_letters`, with the last index representing the EOS marker.\n",
    "def targetTensor(line):\n",
    "    letter_indexes = [all_letters.find(line[li]) for li in range(1, len(line))]\n",
    "    letter_indexes.append(n_letters - 1)  #EOS\n",
    "    return torch.LongTensor(letter_indexes)"
   ],
   "id": "468680ca1b0d33b6",
   "outputs": [],
   "execution_count": 465
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-10T23:44:00.903438Z",
     "start_time": "2025-03-10T23:44:00.901768Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Make category, input, and target tensors form a random category, line pair\n",
    "def randomTrainingExample():\n",
    "    category, line = randomTrainingPair()\n",
    "    category_tensor = categoryTensor(category)\n",
    "    input_line_tensor = inputTensor(line)\n",
    "    target_line_tensor = targetTensor(line)\n",
    "    return category_tensor, input_line_tensor, target_line_tensor"
   ],
   "id": "b7449dcd5466b37e",
   "outputs": [],
   "execution_count": 466
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Training the Network",
   "id": "35da2d136f2e4a7c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-10T23:44:00.948088Z",
     "start_time": "2025-03-10T23:44:00.944775Z"
    }
   },
   "cell_type": "code",
   "source": [
    "criterion = nn.NLLLoss()\n",
    "\n",
    "learning_rate = 0.0005\n",
    "epochs = 5  # Define the number of epochs for training\n",
    "\n",
    "def train(category_tensor, input_line_tensor, target_line_tensor):\n",
    "    target_line_tensor.unsqueeze_(-1)\n",
    "    hidden = rnn.initHidden()\n",
    "    rnn.zero_grad()\n",
    "    loss = 0  # Initialize loss for the current iteration\n",
    "    correct_predictions = 0  # Initialize correct predictions counter\n",
    "\n",
    "    for i in range(input_line_tensor.size(0)):\n",
    "        output, hidden = rnn(category_tensor, input_line_tensor[i], hidden)\n",
    "        l = criterion(output, target_line_tensor[i])\n",
    "        loss += l\n",
    "\n",
    "        # Track the correct predictions\n",
    "        topv, topi = output.topk(1)\n",
    "        if topi[0].item() == target_line_tensor[i].item():\n",
    "            correct_predictions += 1\n",
    "\n",
    "    loss.backward()\n",
    "\n",
    "    for p in rnn.parameters():\n",
    "        p.data.add_(p.grad.data, alpha=-learning_rate)\n",
    "\n",
    "    accuracy = correct_predictions / input_line_tensor.size(0)  # Calculate accuracy for the example\n",
    "    return output, loss.item() / input_line_tensor.size(0), accuracy\n",
    "\n",
    "# New wrapper function to train over multiple epochs\n",
    "def train_with_epochs(epochs, n_iters):\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        total_loss = 0  # Reset total loss for the current epoch\n",
    "        total_accuracy = 0  # Reset total accuracy for the current epoch\n",
    "        start = time.time()  # Track the start time for the epoch\n",
    "        print(f\"Epoch {epoch}/{epochs} Starting...\")\n",
    "\n",
    "        for iter in range(1, n_iters + 1):\n",
    "            category_tensor, input_line_tensor, target_line_tensor = randomTrainingExample()\n",
    "            _, loss, accuracy = train(category_tensor, input_line_tensor, target_line_tensor)\n",
    "            total_loss += loss\n",
    "            total_accuracy += accuracy\n",
    "\n",
    "            # Print progress at regular intervals\n",
    "            if iter % print_every == 0:\n",
    "                print(f'{timeSince(start)} (Iter {iter}/{n_iters}, Epoch {epoch}) Loss: {loss:.4f}, Accuracy: {accuracy:.4f}')\n",
    "\n",
    "        avg_loss = total_loss / n_iters\n",
    "        avg_accuracy = total_accuracy / n_iters * 100  # Calculate average accuracy as a percentage\n",
    "        print(f\"Epoch {epoch}/{epochs} completed. Average Loss: {avg_loss:.4f}, Accuracy: {avg_accuracy:.2f}%\\n\")"
   ],
   "id": "2e877eb366a50328",
   "outputs": [],
   "execution_count": 467
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-10T23:44:00.990973Z",
     "start_time": "2025-03-10T23:44:00.988979Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import time\n",
    "import math\n",
    "\n",
    "\n",
    "def timeSince(since):\n",
    "    now = time.time()  # Get the current time in seconds since the epoch.\n",
    "    s = now - since  # Calculate the elapsed time in seconds.\n",
    "    m = math.floor(s / 60)  # Convert the elapsed time to minutes.\n",
    "    s -= m * 60  # Calculate the remaining seconds after minutes.\n",
    "    return '%dm %ds' % (m, s)  # Format the elapsed time as a string \"Xm Ys\"."
   ],
   "id": "649adde5648a3c2b",
   "outputs": [],
   "execution_count": 468
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-10T23:50:02.136286Z",
     "start_time": "2025-03-10T23:44:01.034681Z"
    }
   },
   "cell_type": "code",
   "source": [
    "rnn = RNN(n_letters, 128, n_letters)\n",
    "\n",
    "n_iters = 100000\n",
    "print_every = 5000\n",
    "plot_every = 500\n",
    "all_losses = []\n",
    "total_loss = 0 # Reset every ``plot_every`` ``iters``\n",
    "\n",
    "start = time.time()\n",
    "train_with_epochs(epochs=epochs, n_iters=n_iters)\n",
    "\n",
    "# for iter in range(1, n_iters + 1):\n",
    "#     output, loss = train_with_epochs(epochs=epochs, n_iters=n_iters)\n",
    "#\n",
    "#     total_loss += loss\n",
    "#\n",
    "#     if iter % print_every == 0:\n",
    "#         print('%s (%d %d%%) %.4f' % (timeSince(start), iter, iter / n_iters * 100, loss))\n",
    "#\n",
    "#     if iter % plot_every == 0:\n",
    "#         all_losses.append(total_loss / plot_every)\n",
    "#         total_loss = 0"
   ],
   "id": "85adf106e66a9a0a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5 Starting...\n",
      "0m 3s (Iter 5000/100000, Epoch 1) Loss: 2.8933, Accuracy: 0.0000\n",
      "0m 7s (Iter 10000/100000, Epoch 1) Loss: 3.2078, Accuracy: 0.1429\n",
      "0m 10s (Iter 15000/100000, Epoch 1) Loss: 3.1571, Accuracy: 0.1333\n",
      "0m 14s (Iter 20000/100000, Epoch 1) Loss: 2.7336, Accuracy: 0.2500\n",
      "0m 17s (Iter 25000/100000, Epoch 1) Loss: 2.8372, Accuracy: 0.1429\n",
      "0m 21s (Iter 30000/100000, Epoch 1) Loss: 3.3337, Accuracy: 0.2727\n",
      "0m 25s (Iter 35000/100000, Epoch 1) Loss: 2.2124, Accuracy: 0.4286\n",
      "0m 28s (Iter 40000/100000, Epoch 1) Loss: 2.5239, Accuracy: 0.3333\n",
      "0m 32s (Iter 45000/100000, Epoch 1) Loss: 2.3395, Accuracy: 0.2000\n",
      "0m 35s (Iter 50000/100000, Epoch 1) Loss: 2.8160, Accuracy: 0.1250\n",
      "0m 39s (Iter 55000/100000, Epoch 1) Loss: 1.6864, Accuracy: 0.6667\n",
      "0m 43s (Iter 60000/100000, Epoch 1) Loss: 2.3669, Accuracy: 0.2500\n",
      "0m 46s (Iter 65000/100000, Epoch 1) Loss: 2.6704, Accuracy: 0.2000\n",
      "0m 50s (Iter 70000/100000, Epoch 1) Loss: 2.0719, Accuracy: 0.5000\n",
      "0m 53s (Iter 75000/100000, Epoch 1) Loss: 2.0036, Accuracy: 0.3333\n",
      "0m 57s (Iter 80000/100000, Epoch 1) Loss: 1.7409, Accuracy: 0.6667\n",
      "1m 1s (Iter 85000/100000, Epoch 1) Loss: 2.9946, Accuracy: 0.1667\n",
      "1m 4s (Iter 90000/100000, Epoch 1) Loss: 2.2441, Accuracy: 0.4286\n",
      "1m 8s (Iter 95000/100000, Epoch 1) Loss: 3.1570, Accuracy: 0.1429\n",
      "1m 11s (Iter 100000/100000, Epoch 1) Loss: 2.3718, Accuracy: 0.3333\n",
      "Epoch 1/5 completed. Average Loss: 2.5046, Accuracy: 29.70%\n",
      "\n",
      "Epoch 2/5 Starting...\n",
      "0m 3s (Iter 5000/100000, Epoch 2) Loss: 2.7861, Accuracy: 0.1250\n",
      "0m 7s (Iter 10000/100000, Epoch 2) Loss: 2.5891, Accuracy: 0.1429\n",
      "0m 10s (Iter 15000/100000, Epoch 2) Loss: 2.4813, Accuracy: 0.2222\n",
      "0m 14s (Iter 20000/100000, Epoch 2) Loss: 2.4172, Accuracy: 0.0000\n",
      "0m 18s (Iter 25000/100000, Epoch 2) Loss: 1.9438, Accuracy: 0.0000\n",
      "0m 21s (Iter 30000/100000, Epoch 2) Loss: 2.5839, Accuracy: 0.2500\n",
      "0m 25s (Iter 35000/100000, Epoch 2) Loss: 3.4053, Accuracy: 0.0000\n",
      "0m 29s (Iter 40000/100000, Epoch 2) Loss: 3.3798, Accuracy: 0.2857\n",
      "0m 32s (Iter 45000/100000, Epoch 2) Loss: 2.7502, Accuracy: 0.2857\n",
      "0m 36s (Iter 50000/100000, Epoch 2) Loss: 1.8136, Accuracy: 0.4286\n",
      "0m 39s (Iter 55000/100000, Epoch 2) Loss: 2.2791, Accuracy: 0.1250\n",
      "0m 43s (Iter 60000/100000, Epoch 2) Loss: 2.7766, Accuracy: 0.1250\n",
      "0m 47s (Iter 65000/100000, Epoch 2) Loss: 2.1867, Accuracy: 0.1429\n",
      "0m 50s (Iter 70000/100000, Epoch 2) Loss: 2.2302, Accuracy: 0.6667\n",
      "0m 54s (Iter 75000/100000, Epoch 2) Loss: 3.1537, Accuracy: 0.0000\n",
      "0m 58s (Iter 80000/100000, Epoch 2) Loss: 2.5233, Accuracy: 0.0000\n",
      "1m 1s (Iter 85000/100000, Epoch 2) Loss: 2.6215, Accuracy: 0.2727\n",
      "1m 5s (Iter 90000/100000, Epoch 2) Loss: 3.3830, Accuracy: 0.3333\n",
      "1m 8s (Iter 95000/100000, Epoch 2) Loss: 2.4540, Accuracy: 0.5000\n",
      "1m 12s (Iter 100000/100000, Epoch 2) Loss: 3.4884, Accuracy: 0.0000\n",
      "Epoch 2/5 completed. Average Loss: 2.2517, Accuracy: 34.07%\n",
      "\n",
      "Epoch 3/5 Starting...\n",
      "0m 3s (Iter 5000/100000, Epoch 3) Loss: 0.8788, Accuracy: 1.0000\n",
      "0m 7s (Iter 10000/100000, Epoch 3) Loss: 1.5872, Accuracy: 0.6000\n",
      "0m 10s (Iter 15000/100000, Epoch 3) Loss: 3.0929, Accuracy: 0.1429\n",
      "0m 14s (Iter 20000/100000, Epoch 3) Loss: 2.1881, Accuracy: 0.3333\n",
      "0m 17s (Iter 25000/100000, Epoch 3) Loss: 2.1313, Accuracy: 0.5000\n",
      "0m 21s (Iter 30000/100000, Epoch 3) Loss: 2.1972, Accuracy: 0.1429\n",
      "0m 25s (Iter 35000/100000, Epoch 3) Loss: 2.8750, Accuracy: 0.1667\n",
      "0m 28s (Iter 40000/100000, Epoch 3) Loss: 1.9111, Accuracy: 0.5000\n",
      "0m 32s (Iter 45000/100000, Epoch 3) Loss: 3.0108, Accuracy: 0.2500\n",
      "0m 35s (Iter 50000/100000, Epoch 3) Loss: 1.9665, Accuracy: 0.4286\n",
      "0m 39s (Iter 55000/100000, Epoch 3) Loss: 1.8527, Accuracy: 0.2500\n",
      "0m 42s (Iter 60000/100000, Epoch 3) Loss: 2.6769, Accuracy: 0.3333\n",
      "0m 46s (Iter 65000/100000, Epoch 3) Loss: 2.6890, Accuracy: 0.2000\n",
      "0m 50s (Iter 70000/100000, Epoch 3) Loss: 1.8491, Accuracy: 0.3333\n",
      "0m 53s (Iter 75000/100000, Epoch 3) Loss: 1.6212, Accuracy: 0.7500\n",
      "0m 57s (Iter 80000/100000, Epoch 3) Loss: 1.7362, Accuracy: 0.4000\n",
      "1m 1s (Iter 85000/100000, Epoch 3) Loss: 1.8895, Accuracy: 0.4444\n",
      "1m 4s (Iter 90000/100000, Epoch 3) Loss: 2.0938, Accuracy: 0.4000\n",
      "1m 8s (Iter 95000/100000, Epoch 3) Loss: 3.4447, Accuracy: 0.0000\n",
      "1m 12s (Iter 100000/100000, Epoch 3) Loss: 1.6491, Accuracy: 0.6000\n",
      "Epoch 3/5 completed. Average Loss: 2.1849, Accuracy: 35.27%\n",
      "\n",
      "Epoch 4/5 Starting...\n",
      "0m 3s (Iter 5000/100000, Epoch 4) Loss: 1.1034, Accuracy: 0.7500\n",
      "0m 7s (Iter 10000/100000, Epoch 4) Loss: 1.9035, Accuracy: 0.4000\n",
      "0m 11s (Iter 15000/100000, Epoch 4) Loss: 2.4560, Accuracy: 0.4286\n",
      "0m 14s (Iter 20000/100000, Epoch 4) Loss: 1.9744, Accuracy: 0.6667\n",
      "0m 18s (Iter 25000/100000, Epoch 4) Loss: 2.4158, Accuracy: 0.2857\n",
      "0m 21s (Iter 30000/100000, Epoch 4) Loss: 1.7838, Accuracy: 0.4286\n",
      "0m 25s (Iter 35000/100000, Epoch 4) Loss: 2.8095, Accuracy: 0.1250\n",
      "0m 29s (Iter 40000/100000, Epoch 4) Loss: 2.5247, Accuracy: 0.1667\n",
      "0m 32s (Iter 45000/100000, Epoch 4) Loss: 2.6606, Accuracy: 0.4000\n",
      "0m 36s (Iter 50000/100000, Epoch 4) Loss: 1.9959, Accuracy: 0.6667\n",
      "0m 40s (Iter 55000/100000, Epoch 4) Loss: 2.7125, Accuracy: 0.1667\n",
      "0m 43s (Iter 60000/100000, Epoch 4) Loss: 2.5205, Accuracy: 0.5000\n",
      "0m 47s (Iter 65000/100000, Epoch 4) Loss: 1.9276, Accuracy: 0.6000\n",
      "0m 51s (Iter 70000/100000, Epoch 4) Loss: 2.7062, Accuracy: 0.3333\n",
      "0m 54s (Iter 75000/100000, Epoch 4) Loss: 2.1791, Accuracy: 0.5000\n",
      "0m 58s (Iter 80000/100000, Epoch 4) Loss: 1.9601, Accuracy: 0.6000\n",
      "1m 2s (Iter 85000/100000, Epoch 4) Loss: 2.4042, Accuracy: 0.1667\n",
      "1m 5s (Iter 90000/100000, Epoch 4) Loss: 2.2874, Accuracy: 0.2857\n",
      "1m 9s (Iter 95000/100000, Epoch 4) Loss: 1.8845, Accuracy: 0.5000\n",
      "1m 12s (Iter 100000/100000, Epoch 4) Loss: 1.7489, Accuracy: 0.5000\n",
      "Epoch 4/5 completed. Average Loss: 2.1392, Accuracy: 36.13%\n",
      "\n",
      "Epoch 5/5 Starting...\n",
      "0m 3s (Iter 5000/100000, Epoch 5) Loss: 1.9660, Accuracy: 0.4000\n",
      "0m 7s (Iter 10000/100000, Epoch 5) Loss: 1.7298, Accuracy: 0.5000\n",
      "0m 10s (Iter 15000/100000, Epoch 5) Loss: 2.2218, Accuracy: 0.4286\n",
      "0m 14s (Iter 20000/100000, Epoch 5) Loss: 2.4323, Accuracy: 0.4000\n",
      "0m 17s (Iter 25000/100000, Epoch 5) Loss: 2.8038, Accuracy: 0.0000\n",
      "0m 21s (Iter 30000/100000, Epoch 5) Loss: 2.6539, Accuracy: 0.1818\n",
      "0m 25s (Iter 35000/100000, Epoch 5) Loss: 2.3080, Accuracy: 0.3000\n",
      "0m 28s (Iter 40000/100000, Epoch 5) Loss: 2.9985, Accuracy: 0.5000\n",
      "0m 32s (Iter 45000/100000, Epoch 5) Loss: 1.9616, Accuracy: 0.5000\n",
      "0m 35s (Iter 50000/100000, Epoch 5) Loss: 0.6596, Accuracy: 1.0000\n",
      "0m 39s (Iter 55000/100000, Epoch 5) Loss: 2.6379, Accuracy: 0.2500\n",
      "0m 42s (Iter 60000/100000, Epoch 5) Loss: 1.5508, Accuracy: 0.6000\n",
      "0m 46s (Iter 65000/100000, Epoch 5) Loss: 1.7238, Accuracy: 0.5000\n",
      "0m 50s (Iter 70000/100000, Epoch 5) Loss: 2.9391, Accuracy: 0.2500\n",
      "0m 53s (Iter 75000/100000, Epoch 5) Loss: 2.6653, Accuracy: 0.2308\n",
      "0m 57s (Iter 80000/100000, Epoch 5) Loss: 2.7357, Accuracy: 0.2222\n",
      "1m 1s (Iter 85000/100000, Epoch 5) Loss: 0.9338, Accuracy: 0.6667\n",
      "1m 4s (Iter 90000/100000, Epoch 5) Loss: 1.6869, Accuracy: 0.3333\n",
      "1m 8s (Iter 95000/100000, Epoch 5) Loss: 1.4596, Accuracy: 0.3333\n",
      "1m 11s (Iter 100000/100000, Epoch 5) Loss: 1.2944, Accuracy: 0.6667\n",
      "Epoch 5/5 completed. Average Loss: 2.1138, Accuracy: 36.52%\n",
      "\n"
     ]
    }
   ],
   "execution_count": 469
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Plotting the Losses",
   "id": "43f1d1d606aabe1c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-10T23:50:02.187458Z",
     "start_time": "2025-03-10T23:50:02.145242Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(all_losses)\n",
    "plt.title(\"Training Loss Over Time\")  # Add title\n",
    "plt.xlabel(\"Iterations\")  # Add x-axis label\n",
    "plt.ylabel(\"Loss\")  # Add y-axis label"
   ],
   "id": "f39999a65dad66d",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Loss')"
      ]
     },
     "execution_count": 470,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 470
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Sampling the Network",
   "id": "f654299c5769c882"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-10T23:50:02.195986Z",
     "start_time": "2025-03-10T23:50:02.189571Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Maximum number of characters to be generated in a name\n",
    "max_length = 20\n",
    "\n",
    "\n",
    "# Sample from a category and starting letter\n",
    "# The function generates a name by sampling one character at a time, starting with 'start_letter'.\n",
    "# It uses the trained RNN to predict the next character based on the category and previous hidden state.\n",
    "def sample(category, start_letter='A'):\n",
    "    with torch.no_grad():  # no need to track history in sampling\n",
    "        # Create one-hot encoded tensors for the category and the starting letter\n",
    "        category_tensor = categoryTensor(category)\n",
    "        input = inputTensor(start_letter)\n",
    "        # Initialize the hidden state for the RNN\n",
    "        hidden = rnn.initHidden()\n",
    "\n",
    "        # Initialize the generated name as the starting letter\n",
    "        output_name = start_letter\n",
    "\n",
    "        for i in range(max_length):\n",
    "            # Get output and updated hidden state from the RNN\n",
    "            output, hidden = rnn(category_tensor, input[0], hidden)\n",
    "            # Get the most likely character index (highest probability)\n",
    "            topv, topi = output.topk(1)\n",
    "            topi = topi[0][0]\n",
    "            # Stop if the EOS (End of String) index is reached\n",
    "            if topi == n_letters - 1:\n",
    "                break\n",
    "            else:\n",
    "                # Append the predicted character to the output name\n",
    "                letter = all_letters[topi]\n",
    "                output_name += letter\n",
    "            # Create the input tensor for the next step using the predicted character\n",
    "            input = inputTensor(letter)\n",
    "\n",
    "        return output_name\n",
    "\n",
    "\n",
    "# Get multiple samples from one category and multiple starting letters\n",
    "# For a given category (e.g., language), the function generates names starting with each letter in 'start_letters'.\n",
    "def samples(category, start_letters='ABC'):\n",
    "    for start_letter in start_letters:\n",
    "        print(sample(category, start_letter))\n",
    "\n",
    "\n",
    "# Generate and print samples for selected categories and starting letters\n",
    "samples('Russian', 'RUS')  # Names in the Russian category starting with 'R', 'U', and 'S'\n",
    "samples('German', 'GER')  # Names in the German category starting with 'G', 'E', and 'R'\n",
    "samples('Spanish', 'SPA')  # Names in the Spanish category starting with 'S', 'P', and 'A'\n",
    "samples('Chinese', 'CHI')  # Names in the Chinese category starting with 'C', 'H', and 'I'"
   ],
   "id": "303f044c772962e5",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Romankov\n",
      "Urishin\n",
      "Sakovanov\n",
      "Grenter\n",
      "Esterr\n",
      "Roser\n",
      "Santar\n",
      "Pantera\n",
      "Alaran\n",
      "Che\n",
      "Han\n",
      "Ina\n"
     ]
    }
   ],
   "execution_count": 471
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-10T23:50:02.242730Z",
     "start_time": "2025-03-10T23:50:02.241246Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "f368f15a235453ea",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
