{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# [Custom Dataset (Cats & Dogs)](https://www.youtube.com/watch?v=ZoZHd0Zm3RY&list=PLLO3XdUcTFzwZNl2lpg_PTbUSLzHBZoK_&index=8)",
   "id": "8a77807f92f26ee"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Import Packages",
   "id": "605651c899cab84c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-15T16:42:43.550543Z",
     "start_time": "2025-02-15T16:42:41.857620Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from skimage import io\n",
    "from torchvision import transforms"
   ],
   "id": "fbc121e30a2defb3",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Data Preparation\n",
    "[Kaggle Data](https://www.kaggle.com/c/dogs-vs-cats/overview)"
   ],
   "id": "b20c31f230617a3b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-15T16:42:51.140295Z",
     "start_time": "2025-02-15T16:42:51.071303Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Define the train folder path\n",
    "train_dir = os.path.join('data', 'dogs-vs-cats', 'train')  # Update path accordingly\n",
    "\n",
    "# Initialize a list to hold file data\n",
    "data = []\n",
    "\n",
    "# Iterate through all files in the train folder\n",
    "for file_name in os.listdir(train_dir):\n",
    "    if os.path.isfile(os.path.join(train_dir, file_name)):\n",
    "        if 'cat' in file_name:\n",
    "            label = 0\n",
    "            num_part = int(file_name.split('cat.')[1].split('.jpg')[0])  # Extract the number part\n",
    "        elif 'dog' in file_name:\n",
    "            label = 1\n",
    "            num_part = int(file_name.split('dog.')[1].split('.jpg')[0])  # Extract the number part\n",
    "        else:\n",
    "            continue  # Skip files that are neither cat nor dog\n",
    "        data.append({'id': file_name, 'label': label, 'num': num_part})\n",
    "\n",
    "# Convert the data into a DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Sort the DataFrame by label (cats first, dogs second), and then by the numerical part\n",
    "df_sorted = df.sort_values(by=['label', 'num']).drop(columns=['num'])  # Drop 'num' after sorting\n",
    "\n",
    "# Save the sorted DataFrame to a CSV file\n",
    "output_csv = os.path.join('data', 'dogs-vs-cats', 'cats_dogs_labels_sorted.csv')\n",
    "df_sorted.to_csv(output_csv, index=False)  # Save without the index column\n",
    "\n",
    "print(f\"CSV file saved to {output_csv}\")\n"
   ],
   "id": "f9eb449092a7cfa4",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV file saved to data/dogs-vs-cats/cats_dogs_labels_sorted.csv\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-15T16:45:14.897028Z",
     "start_time": "2025-02-15T16:45:14.894249Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class CatsAndDogsDataset(Dataset):\n",
    "    def __init__(self, csv_file, root_dir, transform=None):\n",
    "        \"\"\"\n",
    "        Initialize the CatsAndDogsDataset.\n",
    "\n",
    "        Parameters:\n",
    "        csv_file (str): Path to the CSV file containing image file names and labels.\n",
    "        root_dir (str): Directory containing the image files.\n",
    "        transform (callable, optional): Transformations to be applied on the images (e.g., scaling, normalization, etc.).\n",
    "        \"\"\"\n",
    "        self.annotations = pd.read_csv(csv_file)  # Load the CSV file into a DataFrame.\n",
    "        self.root_dir = root_dir  # Path to the directory containing image files.\n",
    "        self.transform = transform  # Transformations to apply to images during data retrieval (if specified).\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"\n",
    "        Return the total number of samples in the dataset.\n",
    "\n",
    "        Returns:\n",
    "        int: Number of rows in the annotations DataFrame, representing the dataset size.\n",
    "        \"\"\"\n",
    "        return len(self.annotations)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"\n",
    "        Retrieve a single data sample (image and label) by index.\n",
    "\n",
    "        Parameters:\n",
    "        idx (int): Index of the sample to retrieve.\n",
    "\n",
    "        Returns:\n",
    "        tuple: A tuple containing the transformed image (torch.Tensor) and the corresponding label (torch.Tensor).\n",
    "        \"\"\"\n",
    "        # Full path to the image file corresponding to the given index.\n",
    "        img_path = os.path.join(self.root_dir, self.annotations.iloc[idx, 0])\n",
    "\n",
    "        # Load the image from the specified path. `io.imread` reads the image as a NumPy array.\n",
    "        image = io.imread(img_path)\n",
    "\n",
    "        # Retrieve the label from the DataFrame and convert it to a tensor (integer).\n",
    "        y_label = torch.tensor(int(self.annotations.iloc[idx, 1]))\n",
    "\n",
    "        # Apply transformations to the image, if any are specified.\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        # Return the transformed image and corresponding label as a tuple.\n",
    "        return image, y_label"
   ],
   "id": "739093a639b2ff17",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-15T16:45:35.074534Z",
     "start_time": "2025-02-15T16:45:35.063632Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Instantiate a CatsAndDogsDataset object using the sorted CSV file and the directory containing the images.\n",
    "# The transform parameter is set to 'transforms.ToTensor()', which converts images to PyTorch tensors.\n",
    "dataset = CatsAndDogsDataset(\n",
    "    csv_file='data/dogs-vs-cats/cats_dogs_labels_sorted.csv',\n",
    "    root_dir='data/dogs-vs-cats/train',\n",
    "    transform=transforms.ToTensor()\n",
    ")\n",
    "\n",
    "# Print the total number of samples in the dataset by calling the __len__ method.\n",
    "print(len(dataset))\n",
    "\n",
    "# Split the dataset randomly into a training set (20000 samples) and a test set (5000 samples).\n",
    "# The random_split function ensures the specified sizes for the train and test sets.\n",
    "train_set, test_set = torch.utils.data.random_split(dataset, [20000, 5000])\n",
    "\n",
    "# Create a DataLoader for the training set to enable batch processing.\n",
    "# The batch size is set to 16, and shuffling ensures that the samples in each batch are randomized.\n",
    "train_loader = DataLoader(train_set, batch_size=16, shuffle=True)\n",
    "\n",
    "# Create a DataLoader for the test set.\n",
    "# The batch size is also set to 16, and shuffling is enabled for randomized testing batches.\n",
    "test_loader = DataLoader(test_set, batch_size=16, shuffle=True)"
   ],
   "id": "67b2bc7ad435515b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25000\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "bc6efcbdbd2aac49"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
